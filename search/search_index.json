{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Sub Pages Homelab Tech","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#sub-pages","text":"Homelab Tech","title":"Sub Pages"},{"location":"Homelab/How-to-Start-a-Homelab/","text":"Hypervisors - The software that will run the virtual machines (VM) for the lab Type 1 Proxmox ESXi Free XCP-ng Type 2 VirtualBox VMWare Workstation Networking Routers Opnsense OpenWRT Prerequisites SSH key created on your local computer Debian 11 ISO downloaded Windows Server 2022 ISO downloaded Windows 10 ISO downloaded Domain name for your Linux lab decided (example.lab.com) Domain name for your Windows lab decided (example.lab.com) A domain name on the internet Linux Skills Setup a DHCP server or modify your current one to create a DHCP scope that will give you 50 IP addresses outside of this scope Create a Debian 11 VM with 1GB of RAM and 1 vCPU. Set a static IP that is outside of your DHCP scope and change the hostname mkdocs.domain.com (replace domain.com with your chosen domain name) Create a user for yourself, add yourself to the sudoers group, and login to your new user You might want to look up what NOPASSWD is and what it does, and decide if you want to change that setting Install updates and the packages listed below an python3 python3-pip vim git curl wget unzip Enable unattended upgrades Deny root login over SSH and disable password login over SSH Disconnect from the Debian VM and reconnect with your local user using an SSH key Install MkDocs Enable the firewall and permit the ports for MkDocs and SSH, deny all other ports Verify you can access MkDocs from the browser on your local computer Document your network setup, and anything you need to remember from setting up this VM. This is now where all of the documentation you create for this will be stored. Determine how you are going to backup this VM and the rest of your VMs Create 2 Debian 11 VMs with 4GB of RAM and 2 vCPUs in the same manner as above, name these docker-01.domain.com and docker-02.domain.com Figure out how to allow Ansible to connect to your new VM - https://docs.ansible.com/ansible/latest/user_guide/connection_details.html Install Ansible on your local computer Create an Ansible playbook to configure your two new servers with below settings: Deny root login over SSH Disable password login over SSH Set this as the message of the day for the server - https://raw.githubusercontent.com/jwandrews99/Linux-Automation/master/misc/motd.sh Install the following packages python3 python3-pip vim git curl wget unzip Install docker and docker-compose Create a user for yourself Add your user to the docker group On docker-01 install the Pi-hole container by using a docker compose file Configure Pi-hole through the webui and add the blocklists at https://v.firebog.net/hosts/lists.php?type=tick On docker-02 install the Pi-hole container using a docker compose file Setup Gravity Sync to keep the two servers in sync Add the domain names of your 3 VMs to the Pi-hole local DNS, you can now resolve these hostnames in your browser From now on, when you create a service with a hostname, add it to the Pi-hole local DNS On docker-01 install and setup Portainer On docker-01 install and setup Uptime Kuma Configure Uptime Kuma to send alerts to a Discord server when one of your services loses connectivity On docker-02 install and setup Dashy Configure Cloudflare Tunnels to allow secure access to Dashy from the internet using your internet facing domain name With Dashy secured, add your Pi-hole, Uptime Kuma, and MkDocs to Cloudflare Tunnels and add them to your Dashy dashboard Create an Ansible playbook to update all of your servers Create a GitHub account and add your SSH key to it Create a repository called Ansible and commit your playbook to it through the command line Create a repository called Docker and commit your docker-compose files to it through the command line Publish your MkDocs documentation on GitHub using GitHub Pages Setup a custom domain for your documentation on GitHub - docs.domain.com Configure GitHub Actions to automatically update your MkDocs website when changes are pushed to the repository Windows Skills Create 4 Windows Server 2022 VMs and 1 Windows 10 VM. Set one up as the primary domain controller, one as the secondary domain controller, and join the other 2 to the domain as member servers Create 4 Active Directory OUs. One for users, one for domain admins, one for groups, and one for computers Create 2 standard users in AD named test1 and test2 with the GUI and place them in the users group Create a Security Group and name it test-group, place this in the groups OU, add the test2 user to this group Join your Windows 10 VM to the domain you created and place it in the computers OU Create a domain admin in AD and add it to the domain admins OU with PowerShell Create a reverse look up zone in DNS Setup DNS scavenging Setup DHCP on the primary domain controller and configure a DHCP scope On the Windows 10 VM you created, install Remote Server Administration Tools (RSAT) Open Active Directory Users and Computers from within RSAT and take a look around, look at DHCP and DNS too - This is where most management is done Determine what domain controller is holding the FSMO roles with the GUI, PowerShell, and the Windows command prompt Install DFS and file server features on the 2 member servers Create a file share on both servers with the same name and place a file in each share, with different names - testfile1 testfile2 Create a DFS namespace and add those shares to the name space Create a DFS replication group, setup two way replication Use Group Policy to map the DFS namespace when user test1 logs in Use group policy to install Google Chrome and the uBlock Origin extension Create a domain password policy in Group Policy Print a list of all domain users using PowerShell and then filter that to show name only Use PowerShell to see the date the password was last changed fort he user test1 Print a list of all domain computers using PowerShell and then filter that to show name only Create 10 new users in AD from a CSV file using PowerShell Use PowerShell to set the Company and Division of all of your users in AD (This is something I did just this last week) Remove one of these users from AD using PowerShell","title":"How to Start a Homelab"},{"location":"Homelab/How-to-Start-a-Homelab/#hypervisors-the-software-that-will-run-the-virtual-machines-vm-for-the-lab","text":"Type 1 Proxmox ESXi Free XCP-ng Type 2 VirtualBox VMWare Workstation","title":"Hypervisors - The software that will run the virtual machines (VM) for the lab"},{"location":"Homelab/How-to-Start-a-Homelab/#networking","text":"Routers Opnsense OpenWRT","title":"Networking"},{"location":"Homelab/How-to-Start-a-Homelab/#prerequisites","text":"SSH key created on your local computer Debian 11 ISO downloaded Windows Server 2022 ISO downloaded Windows 10 ISO downloaded Domain name for your Linux lab decided (example.lab.com) Domain name for your Windows lab decided (example.lab.com) A domain name on the internet","title":"Prerequisites"},{"location":"Homelab/How-to-Start-a-Homelab/#linux-skills","text":"Setup a DHCP server or modify your current one to create a DHCP scope that will give you 50 IP addresses outside of this scope Create a Debian 11 VM with 1GB of RAM and 1 vCPU. Set a static IP that is outside of your DHCP scope and change the hostname mkdocs.domain.com (replace domain.com with your chosen domain name) Create a user for yourself, add yourself to the sudoers group, and login to your new user You might want to look up what NOPASSWD is and what it does, and decide if you want to change that setting Install updates and the packages listed below an python3 python3-pip vim git curl wget unzip Enable unattended upgrades Deny root login over SSH and disable password login over SSH Disconnect from the Debian VM and reconnect with your local user using an SSH key Install MkDocs Enable the firewall and permit the ports for MkDocs and SSH, deny all other ports Verify you can access MkDocs from the browser on your local computer Document your network setup, and anything you need to remember from setting up this VM. This is now where all of the documentation you create for this will be stored. Determine how you are going to backup this VM and the rest of your VMs Create 2 Debian 11 VMs with 4GB of RAM and 2 vCPUs in the same manner as above, name these docker-01.domain.com and docker-02.domain.com Figure out how to allow Ansible to connect to your new VM - https://docs.ansible.com/ansible/latest/user_guide/connection_details.html Install Ansible on your local computer Create an Ansible playbook to configure your two new servers with below settings: Deny root login over SSH Disable password login over SSH Set this as the message of the day for the server - https://raw.githubusercontent.com/jwandrews99/Linux-Automation/master/misc/motd.sh Install the following packages python3 python3-pip vim git curl wget unzip Install docker and docker-compose Create a user for yourself Add your user to the docker group On docker-01 install the Pi-hole container by using a docker compose file Configure Pi-hole through the webui and add the blocklists at https://v.firebog.net/hosts/lists.php?type=tick On docker-02 install the Pi-hole container using a docker compose file Setup Gravity Sync to keep the two servers in sync Add the domain names of your 3 VMs to the Pi-hole local DNS, you can now resolve these hostnames in your browser From now on, when you create a service with a hostname, add it to the Pi-hole local DNS On docker-01 install and setup Portainer On docker-01 install and setup Uptime Kuma Configure Uptime Kuma to send alerts to a Discord server when one of your services loses connectivity On docker-02 install and setup Dashy Configure Cloudflare Tunnels to allow secure access to Dashy from the internet using your internet facing domain name With Dashy secured, add your Pi-hole, Uptime Kuma, and MkDocs to Cloudflare Tunnels and add them to your Dashy dashboard Create an Ansible playbook to update all of your servers Create a GitHub account and add your SSH key to it Create a repository called Ansible and commit your playbook to it through the command line Create a repository called Docker and commit your docker-compose files to it through the command line Publish your MkDocs documentation on GitHub using GitHub Pages Setup a custom domain for your documentation on GitHub - docs.domain.com Configure GitHub Actions to automatically update your MkDocs website when changes are pushed to the repository","title":"Linux Skills"},{"location":"Homelab/How-to-Start-a-Homelab/#windows-skills","text":"Create 4 Windows Server 2022 VMs and 1 Windows 10 VM. Set one up as the primary domain controller, one as the secondary domain controller, and join the other 2 to the domain as member servers Create 4 Active Directory OUs. One for users, one for domain admins, one for groups, and one for computers Create 2 standard users in AD named test1 and test2 with the GUI and place them in the users group Create a Security Group and name it test-group, place this in the groups OU, add the test2 user to this group Join your Windows 10 VM to the domain you created and place it in the computers OU Create a domain admin in AD and add it to the domain admins OU with PowerShell Create a reverse look up zone in DNS Setup DNS scavenging Setup DHCP on the primary domain controller and configure a DHCP scope On the Windows 10 VM you created, install Remote Server Administration Tools (RSAT) Open Active Directory Users and Computers from within RSAT and take a look around, look at DHCP and DNS too - This is where most management is done Determine what domain controller is holding the FSMO roles with the GUI, PowerShell, and the Windows command prompt Install DFS and file server features on the 2 member servers Create a file share on both servers with the same name and place a file in each share, with different names - testfile1 testfile2 Create a DFS namespace and add those shares to the name space Create a DFS replication group, setup two way replication Use Group Policy to map the DFS namespace when user test1 logs in Use group policy to install Google Chrome and the uBlock Origin extension Create a domain password policy in Group Policy Print a list of all domain users using PowerShell and then filter that to show name only Use PowerShell to see the date the password was last changed fort he user test1 Print a list of all domain computers using PowerShell and then filter that to show name only Create 10 new users in AD from a CSV file using PowerShell Use PowerShell to set the Company and Division of all of your users in AD (This is something I did just this last week) Remove one of these users from AD using PowerShell","title":"Windows Skills"},{"location":"Homelab/Network-Documentation/","text":"Network Information Network Hostname IP Description opnsense.local.rtynerlabs.io 10.1.1.0 Oopnsense router ap1.local.rtynerlabs.io 10.1.1.226 unifi ap running openwrt core-sw-01 10.1.1.254 cisco ws-c3560g-24ps poe gigabit switch Physical Hosts Hostname IP Description pve1.local.rtynerlabs.io 10.1.1.2 primary proxmox host pve2.local.rtynerlabs.io 10.1.1.3 secondary proxmox host truenas.local.rtynerlabs.io 10.1.1.6 bare metal truenas hosting 2 zfs pools Virtual Machines Hostname IP Description opnsense.local.rtynerlabs.io 10.1.1.1 OPNSense router VM docker-1.local.rtynerlabs.io 10.1.1.200 primary docker host for testing traefik.local.rtynerlabs.io 10.1.1.9 traefik reverse proxy nfs-file-1.local.rtynerlabs.io 10.1.1.22 nfs file server hosting 15TB array dns-1.local.rtynerlabs.io 10.1.1.53 pihole dns 1 dns-2.local.rtynerlabs.io 10.1.1.54 pihole dns 2 arch-download.local.rtynerlabs.io 10.1.1.21 arch linux file transfer server ard-dev-1.local.rtynerlabs.io 10.1.1.25 arduino development server nextcloud.local.rtynerlabs.io 10.1.1.20 nextcloud file storage prod-docker-1.local.rtynerlabs.io 10.1.1.10 production docker host 1 prod-docker-2.local.rtynerlabs.io 10.1.1.11 production docker host 2 dc-1.win.rtynerlabs.io 10.1.1.55 primary windows domain controller dc-2.win.rtynerlabs.io 10.1.1.56 read only windows domain controller win-clt-ws1.win.rtynerlabs.io 10.1.1.57 windows 10 client VM Containers Name Host Exposed Port Description eclipse-mosquitto docker-1 1883,9001 mosquitto mqtt server smokeping docker-1 49154 smokeping network ping tester heimdall docker-1 49155,49133 heimdall dashboard plex prod-docker-1 32400 plex media server uptime-kuma prod-docker-1 3001 uptime monitoring portainer prod-docker-1 8000,9443 portainer container manager calibre prod-docker-1 8080 calibre document/ebook server airsonic prod-docker-1 4040 airsonic music server cloudflared prod-docker-1 cloudflare tunnel tautilli prod-docker-1 8181 plex stats dashy prod-docker-1 8093 dashy dashboard nginx-proxy-manager prod-docker-1 80,443 nginx reverse proxy manager navidrome prod-docker-2 4533 navidrome music server youtube-dl material prod-docker-2 17442 youtube dl server phpipam prod-docker-2 8092 ip address management","title":"Network Information"},{"location":"Homelab/Network-Documentation/#network-information","text":"","title":"Network Information"},{"location":"Homelab/Network-Documentation/#network","text":"Hostname IP Description opnsense.local.rtynerlabs.io 10.1.1.0 Oopnsense router ap1.local.rtynerlabs.io 10.1.1.226 unifi ap running openwrt core-sw-01 10.1.1.254 cisco ws-c3560g-24ps poe gigabit switch","title":"Network"},{"location":"Homelab/Network-Documentation/#physical-hosts","text":"Hostname IP Description pve1.local.rtynerlabs.io 10.1.1.2 primary proxmox host pve2.local.rtynerlabs.io 10.1.1.3 secondary proxmox host truenas.local.rtynerlabs.io 10.1.1.6 bare metal truenas hosting 2 zfs pools","title":"Physical Hosts"},{"location":"Homelab/Network-Documentation/#virtual-machines","text":"Hostname IP Description opnsense.local.rtynerlabs.io 10.1.1.1 OPNSense router VM docker-1.local.rtynerlabs.io 10.1.1.200 primary docker host for testing traefik.local.rtynerlabs.io 10.1.1.9 traefik reverse proxy nfs-file-1.local.rtynerlabs.io 10.1.1.22 nfs file server hosting 15TB array dns-1.local.rtynerlabs.io 10.1.1.53 pihole dns 1 dns-2.local.rtynerlabs.io 10.1.1.54 pihole dns 2 arch-download.local.rtynerlabs.io 10.1.1.21 arch linux file transfer server ard-dev-1.local.rtynerlabs.io 10.1.1.25 arduino development server nextcloud.local.rtynerlabs.io 10.1.1.20 nextcloud file storage prod-docker-1.local.rtynerlabs.io 10.1.1.10 production docker host 1 prod-docker-2.local.rtynerlabs.io 10.1.1.11 production docker host 2 dc-1.win.rtynerlabs.io 10.1.1.55 primary windows domain controller dc-2.win.rtynerlabs.io 10.1.1.56 read only windows domain controller win-clt-ws1.win.rtynerlabs.io 10.1.1.57 windows 10 client VM","title":"Virtual Machines"},{"location":"Homelab/Network-Documentation/#containers","text":"Name Host Exposed Port Description eclipse-mosquitto docker-1 1883,9001 mosquitto mqtt server smokeping docker-1 49154 smokeping network ping tester heimdall docker-1 49155,49133 heimdall dashboard plex prod-docker-1 32400 plex media server uptime-kuma prod-docker-1 3001 uptime monitoring portainer prod-docker-1 8000,9443 portainer container manager calibre prod-docker-1 8080 calibre document/ebook server airsonic prod-docker-1 4040 airsonic music server cloudflared prod-docker-1 cloudflare tunnel tautilli prod-docker-1 8181 plex stats dashy prod-docker-1 8093 dashy dashboard nginx-proxy-manager prod-docker-1 80,443 nginx reverse proxy manager navidrome prod-docker-2 4533 navidrome music server youtube-dl material prod-docker-2 17442 youtube dl server phpipam prod-docker-2 8092 ip address management","title":"Containers"},{"location":"Homelab/Proxmox-Notes/","text":"creating vm images with cloud-init https://registry.terraform.io/modules/sdhibit/cloud-init-vm/proxmox/latest/examples/ubuntu_single_vm https://matthewkalnins.com/posts/home-lab-setup-part-1-proxmox-cloud-init/ https://www.cyberciti.biz/faq/how-to-add-ssh-public-key-to-qcow2-linux-cloud-images-using-virt-sysprep/ https://austinsnerdythings.com/2021/08/30/how-to-create-a-proxmox-ubuntu-cloud-init-image/ download cloud image wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img can edit the img and install packages sudo virt-customize -a focal-server-cloudimg-amd64.img --install qemu-guest-agent create vm from cloud image qm create 9000 --name \"ubuntu-2004-cloudinit-template\" --memory 2048 --cores 2 --net0 virtio,bridge = vmbr0 --sshkeys /root/rt_id_rsa.pub sudo qm importdisk 9000 focal-server-cloudimg-amd64.img local-lvm sudo qm set 9000 --scsihw virtio-scsi-pci --scsi0 local-lvm:vm-9000-disk-0 sudo qm set 9000 --boot c --bootdisk scsi0 sudo qm set 9000 --ide2 local-lvm:cloudinit sudo qm set 9000 --serial0 socket --vga sudo qm set 9000 \u2013-agent enabled = 1 set pw for cloud image virt-customize -a focal-server-cloudimg-amd64.img --root-password password:PASSWORD qm create vm with cloudinit #!/bin/bash wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img sudo virt-customize -a focal-server-cloudimg-amd64.img --install qemu-guest-agent # creates a vm with the provided image with 2 sockets, 4 cores each qm create 1000 --memory 4096 --sockets 2 --cores 4 --net0 virtio,bridge = vmbr0 && qm importdisk 1000 focal-server-cloudimg-amd64.img ssd-pool && qm set 1000 --scsihw virtio-scsi-pci --scsi0 ssd-pool:vm-1000-disk-0 --ide2 local-zfs:cloudinit,size = 32G --boot c --bootdisk scsi0 --serial0 socket --vga serial0 qm template 1000 clone, set keys and ip, and start vm qm clone 1000 200 --name rt-prod-docker-1 qm set 200 --sshkeys id_ed25519.pub qm set 200 --ipconfig0 ip = 10 .1.1.200,gw = 10 .1.1.1 qm set 200 --ipconfig0 ip = 10 .1.1.200/24,gw = 10 .1.1.1 qm start 200 ``` ##### add qemu guest agent to cloudinit image ``` bash apt-get install Libguestfs virt-customize -a /path/to/cloud.img --run-command 'apt-get update && apt-get upgrade -y && apt-get install qemu-guest-agent -y' restore vm to different storage qmrestore vzdump-qemu-100-2022_05_24-12_17_21.vma.zst 100 --storage local scripts/setup backup script #!/bin/bash date = $( date +%m-%d-%y ) find /root/backups/dump-*.tar.gz -type d -ctime +10 -exec rm -rf {} \\; tar czvf /home/root/backups/dump- ${ date } .tar.gz /var/lib/vz/dump scp dump- ${ date } .tar.gz rt@207.246.116.69:/home/rt/pve1-backups/ initial setup bash -c \" $( wget -qLO - https://github.com/tteck/Proxmox/raw/main/misc/post-install-v3.sh ) \" dark mode bash < ( curl -s https://raw.githubusercontent.com/Weilbyte/PVEDiscordDark/master/PVEDiscordDark.sh ) install remove node from broken cluster pvecm status pvecm expected 1 pvecm delnode pve-2 zfs error when creating pool in gui command '/sbin/zpool create -o 'ashift=12' big-dick-pool raidz /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ4L9DN /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ516BK /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ49YBN /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ44ZA7' failed: exit code 1 need to create the pool from cli with -f flag zpool create -o -f 'ashift=12' big-dick-pool raidz /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ4L9DN /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ516BK /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ49YBN /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ44ZA7 import zfs pool from other system root@pve-1:~# zpool import pool: boot-pool id: 1932467786112423802 state: ONLINE status: One or more devices are configured to use a non-native block size. Expect reduced performance. action: The pool can be imported using its name or numeric identifier. config: boot-pool ONLINE zd128 ONLINE pool: ssd-mirror id: 3575452547201133070 state: ONLINE status: The pool was last accessed by another system. action: The pool can be imported using its name or numeric identifier and the '-f' flag. see: https://openzfs.github.io/openzfs-docs/msg/ZFS-8000-EY config: ssd-mirror ONLINE mirror-0 ONLINE sdd2 ONLINE sde2 ONLINE pool: big-dick-pool id: 9453892965676340550 state: ONLINE status: The pool was last accessed by another system. action: The pool can be imported using its name or numeric identifier and the '-f' flag. see: https://openzfs.github.io/openzfs-docs/msg/ZFS-8000-EY config: big-dick-pool ONLINE raidz1-0 ONLINE sdb2 ONLINE sdc2 ONLINE sdf2 ONLINE sda2 ONLINE root@pve-1:~# zpool import ssd-mirror cannot import 'ssd-mirror' : pool was previously in use from another system. Last accessed by ( hostid = bf77e045 ) at Mon May 23 20 :42:32 2022 The pool can be imported, use 'zpool import -f' to import the pool. root@pve-1:~# zpool import -f ssd-mirror root@pve-1:~# zpool import -f big-dick-pool pci passthrough remove pci device from vm cli cd /etc/pve/qemu-server ls #look for the VMID name here *.conf cat VMID.conf #in here you will see a line with hostpci qm set $VMID --delete hostpci# blacklist pci device on proxmox # https://old.reddit.com/r/homelab/comments/4t8p4j/freenas_in_proxmox_vm/ lscpi #find your device in here, copy the ID find /sys | grep drivers.*03:00.0 $ /sys/bus/pci/drivers/mpt3sas/0000:03:00.0 # edit /etc/modprobe.d/pve-blacklist.conf and add your device root@pve-1:/etc/modprobe.d# cat pve-blacklist.conf # This file contains a list of modules which are not supported by Proxmox VE # nidiafb see bugreport https://bugzilla.proxmox.com/show_bug.cgi?id=701 blacklist mpt3sas blacklist nvidiafb # update initramfs update-initramfs -k all -u vm booting to passed through hba https://old.reddit.com/r/homelab/comments/4t8p4j/freenas_in_proxmox_vm/ ![[Pasted image 20220522211124.png]] ![[Pasted image 20220522211135.png]] nfs nfs mount error pve < truenas mount system call failed: 500 - creds are wrong in nfs on truenas - set mapall to root and wheel - https://www.truenas.com/community/threads/am-i-too-dumb-to-understand-nfs-permissions.86524/ nfs mount error nfs create storage failed: cfs-lock 'file-storage_cfg' error: got lock request timeout (500) this happens if the share is still attached on another ip, changed ip of truenas and couldn't add new shares https://askubuntu.com/questions/292043/how-to-unmount-nfs-when-server-is-gone mount | grep nfs 10 .1.1.138:/mnt/big-dick-pool/big-dick-pool/pve on /mnt/pve/big-dick-pool type nfs ( rw,relatime,vers = 3 ,rsize = 131072 ,wsize = 131072 ,namlen = 255 ,hard,proto = tcp,timeo = 600 ,retrans = 2 ,sec = sys,mountaddr = 10 .1.1.138,mountvers = 3 ,mountport = 908 ,mountproto = udp,local_lock = none,addr = 10 .1.1.138 ) 10 .1.1.138:/mnt/ssd-mirror/ssd-pool on /mnt/pve/ssd-pool type nfs ( rw,relatime,vers = 3 ,rsize = 131072 ,wsize = 131072 ,namlen = 255 ,hard,proto = tcp,timeo = 600 ,retrans = 2 ,sec = sys,mountaddr = 10 .1.1.138,mountvers = 3 ,mountport = 908 ,mountproto = udp,local_lock = none,addr = 10 .1.1.138 ) umount -f -l /mnt/pve/big-dick-pool umount -f -l /mnt/pve/ssd-pool nfs mounts /mnt/ssd-mirror/ssd-pool /mnt/ssd-mirror/ssd-pool opnsense setting up opnsense on pve https://docs.netgate.com/pfsense/en/latest/recipes/virtualize-proxmox-ve.html#virtualizing-with-proxmox-ve give opnsense two bridged nics that are separate from what proxmox is using i used vmbr1 (eno1) and vmbr0 (eno2) disk testing nfs share fio Disk Speed Tests (Mixed R/W 50/50): --------------------------------- Block Size | 4k (IOPS) | 64k (IOPS) ------ | --- ---- | ---- ---- Read | 7.25 MB/s (1.8k) | 94.72 MB/s (1.4k) Write | 7.27 MB/s (1.8k) | 95.22 MB/s (1.4k) Total | 14.52 MB/s (3.6k) | 189.95 MB/s (2.9k) | | Block Size | 512k (IOPS) | 1m (IOPS) ------ | --- ---- | ---- ---- Read | 80.93 MB/s (158) | 100.83 MB/s (98) Write | 85.23 MB/s (166) | 107.54 MB/s (105) Total | 166.17 MB/s (324) | 208.38 MB/s (203) local fio Disk Speed Tests (Mixed R/W 50/50): --------------------------------- Block Size | 4k (IOPS) | 64k (IOPS) ------ | --- ---- | ---- ---- Read | 45.77 MB/s (11.4k) | 478.09 MB/s (7.4k) Write | 45.86 MB/s (11.4k) | 480.60 MB/s (7.5k) Total | 91.63 MB/s (22.9k) | 958.69 MB/s (14.9k) | | Block Size | 512k (IOPS) | 1m (IOPS) ------ | --- ---- | ---- ---- Read | 1.88 GB/s (3.6k) | 2.51 GB/s (2.4k) Write | 1.98 GB/s (3.8k) | 2.67 GB/s (2.6k) Total | 3.87 GB/s (7.5k) | 5.19 GB/s (5.0k)","title":"Proxmox Notes"},{"location":"Homelab/Proxmox-Notes/#creating-vm-images-with-cloud-init","text":"https://registry.terraform.io/modules/sdhibit/cloud-init-vm/proxmox/latest/examples/ubuntu_single_vm https://matthewkalnins.com/posts/home-lab-setup-part-1-proxmox-cloud-init/ https://www.cyberciti.biz/faq/how-to-add-ssh-public-key-to-qcow2-linux-cloud-images-using-virt-sysprep/ https://austinsnerdythings.com/2021/08/30/how-to-create-a-proxmox-ubuntu-cloud-init-image/ download cloud image wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img can edit the img and install packages sudo virt-customize -a focal-server-cloudimg-amd64.img --install qemu-guest-agent create vm from cloud image qm create 9000 --name \"ubuntu-2004-cloudinit-template\" --memory 2048 --cores 2 --net0 virtio,bridge = vmbr0 --sshkeys /root/rt_id_rsa.pub sudo qm importdisk 9000 focal-server-cloudimg-amd64.img local-lvm sudo qm set 9000 --scsihw virtio-scsi-pci --scsi0 local-lvm:vm-9000-disk-0 sudo qm set 9000 --boot c --bootdisk scsi0 sudo qm set 9000 --ide2 local-lvm:cloudinit sudo qm set 9000 --serial0 socket --vga sudo qm set 9000 \u2013-agent enabled = 1 set pw for cloud image virt-customize -a focal-server-cloudimg-amd64.img --root-password password:PASSWORD","title":"creating vm images with cloud-init"},{"location":"Homelab/Proxmox-Notes/#qm","text":"","title":"qm"},{"location":"Homelab/Proxmox-Notes/#create-vm-with-cloudinit","text":"#!/bin/bash wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img sudo virt-customize -a focal-server-cloudimg-amd64.img --install qemu-guest-agent # creates a vm with the provided image with 2 sockets, 4 cores each qm create 1000 --memory 4096 --sockets 2 --cores 4 --net0 virtio,bridge = vmbr0 && qm importdisk 1000 focal-server-cloudimg-amd64.img ssd-pool && qm set 1000 --scsihw virtio-scsi-pci --scsi0 ssd-pool:vm-1000-disk-0 --ide2 local-zfs:cloudinit,size = 32G --boot c --bootdisk scsi0 --serial0 socket --vga serial0 qm template 1000","title":"create vm with cloudinit"},{"location":"Homelab/Proxmox-Notes/#clone-set-keys-and-ip-and-start-vm","text":"qm clone 1000 200 --name rt-prod-docker-1 qm set 200 --sshkeys id_ed25519.pub qm set 200 --ipconfig0 ip = 10 .1.1.200,gw = 10 .1.1.1 qm set 200 --ipconfig0 ip = 10 .1.1.200/24,gw = 10 .1.1.1 qm start 200 ``` ##### add qemu guest agent to cloudinit image ``` bash apt-get install Libguestfs virt-customize -a /path/to/cloud.img --run-command 'apt-get update && apt-get upgrade -y && apt-get install qemu-guest-agent -y'","title":"clone, set keys and ip, and start vm"},{"location":"Homelab/Proxmox-Notes/#restore-vm-to-different-storage","text":"qmrestore vzdump-qemu-100-2022_05_24-12_17_21.vma.zst 100 --storage local","title":"restore vm to different storage"},{"location":"Homelab/Proxmox-Notes/#scriptssetup","text":"","title":"scripts/setup"},{"location":"Homelab/Proxmox-Notes/#backup-script","text":"#!/bin/bash date = $( date +%m-%d-%y ) find /root/backups/dump-*.tar.gz -type d -ctime +10 -exec rm -rf {} \\; tar czvf /home/root/backups/dump- ${ date } .tar.gz /var/lib/vz/dump scp dump- ${ date } .tar.gz rt@207.246.116.69:/home/rt/pve1-backups/","title":"backup script"},{"location":"Homelab/Proxmox-Notes/#initial-setup","text":"bash -c \" $( wget -qLO - https://github.com/tteck/Proxmox/raw/main/misc/post-install-v3.sh ) \"","title":"initial setup"},{"location":"Homelab/Proxmox-Notes/#dark-mode","text":"bash < ( curl -s https://raw.githubusercontent.com/Weilbyte/PVEDiscordDark/master/PVEDiscordDark.sh ) install","title":"dark mode"},{"location":"Homelab/Proxmox-Notes/#remove-node-from-broken-cluster","text":"pvecm status pvecm expected 1 pvecm delnode pve-2","title":"remove node from broken cluster"},{"location":"Homelab/Proxmox-Notes/#zfs","text":"","title":"zfs"},{"location":"Homelab/Proxmox-Notes/#error-when-creating-pool-in-gui","text":"command '/sbin/zpool create -o 'ashift=12' big-dick-pool raidz /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ4L9DN /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ516BK /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ49YBN /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ44ZA7' failed: exit code 1 need to create the pool from cli with -f flag zpool create -o -f 'ashift=12' big-dick-pool raidz /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ4L9DN /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ516BK /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ49YBN /dev/disk/by-id/ata-ST5000LM000-2AN170_WCJ44ZA7","title":"error when creating pool in gui"},{"location":"Homelab/Proxmox-Notes/#import-zfs-pool-from-other-system","text":"root@pve-1:~# zpool import pool: boot-pool id: 1932467786112423802 state: ONLINE status: One or more devices are configured to use a non-native block size. Expect reduced performance. action: The pool can be imported using its name or numeric identifier. config: boot-pool ONLINE zd128 ONLINE pool: ssd-mirror id: 3575452547201133070 state: ONLINE status: The pool was last accessed by another system. action: The pool can be imported using its name or numeric identifier and the '-f' flag. see: https://openzfs.github.io/openzfs-docs/msg/ZFS-8000-EY config: ssd-mirror ONLINE mirror-0 ONLINE sdd2 ONLINE sde2 ONLINE pool: big-dick-pool id: 9453892965676340550 state: ONLINE status: The pool was last accessed by another system. action: The pool can be imported using its name or numeric identifier and the '-f' flag. see: https://openzfs.github.io/openzfs-docs/msg/ZFS-8000-EY config: big-dick-pool ONLINE raidz1-0 ONLINE sdb2 ONLINE sdc2 ONLINE sdf2 ONLINE sda2 ONLINE root@pve-1:~# zpool import ssd-mirror cannot import 'ssd-mirror' : pool was previously in use from another system. Last accessed by ( hostid = bf77e045 ) at Mon May 23 20 :42:32 2022 The pool can be imported, use 'zpool import -f' to import the pool. root@pve-1:~# zpool import -f ssd-mirror root@pve-1:~# zpool import -f big-dick-pool","title":"import zfs pool from other system"},{"location":"Homelab/Proxmox-Notes/#pci-passthrough","text":"","title":"pci passthrough"},{"location":"Homelab/Proxmox-Notes/#remove-pci-device-from-vm-cli","text":"cd /etc/pve/qemu-server ls #look for the VMID name here *.conf cat VMID.conf #in here you will see a line with hostpci qm set $VMID --delete hostpci#","title":"remove pci device from vm cli"},{"location":"Homelab/Proxmox-Notes/#blacklist-pci-device-on-proxmox","text":"# https://old.reddit.com/r/homelab/comments/4t8p4j/freenas_in_proxmox_vm/ lscpi #find your device in here, copy the ID find /sys | grep drivers.*03:00.0 $ /sys/bus/pci/drivers/mpt3sas/0000:03:00.0 # edit /etc/modprobe.d/pve-blacklist.conf and add your device root@pve-1:/etc/modprobe.d# cat pve-blacklist.conf # This file contains a list of modules which are not supported by Proxmox VE # nidiafb see bugreport https://bugzilla.proxmox.com/show_bug.cgi?id=701 blacklist mpt3sas blacklist nvidiafb # update initramfs update-initramfs -k all -u","title":"blacklist pci device on proxmox"},{"location":"Homelab/Proxmox-Notes/#vm-booting-to-passed-through-hba","text":"https://old.reddit.com/r/homelab/comments/4t8p4j/freenas_in_proxmox_vm/ ![[Pasted image 20220522211124.png]] ![[Pasted image 20220522211135.png]]","title":"vm booting to passed through hba"},{"location":"Homelab/Proxmox-Notes/#nfs","text":"","title":"nfs"},{"location":"Homelab/Proxmox-Notes/#nfs-mount-error-pve-truenas","text":"mount system call failed: 500 - creds are wrong in nfs on truenas - set mapall to root and wheel - https://www.truenas.com/community/threads/am-i-too-dumb-to-understand-nfs-permissions.86524/","title":"nfs mount error pve &lt; truenas"},{"location":"Homelab/Proxmox-Notes/#nfs-mount-error-nfs-create-storage-failed-cfs-lock-file-storage_cfg-error-got-lock-request-timeout-500","text":"this happens if the share is still attached on another ip, changed ip of truenas and couldn't add new shares https://askubuntu.com/questions/292043/how-to-unmount-nfs-when-server-is-gone mount | grep nfs 10 .1.1.138:/mnt/big-dick-pool/big-dick-pool/pve on /mnt/pve/big-dick-pool type nfs ( rw,relatime,vers = 3 ,rsize = 131072 ,wsize = 131072 ,namlen = 255 ,hard,proto = tcp,timeo = 600 ,retrans = 2 ,sec = sys,mountaddr = 10 .1.1.138,mountvers = 3 ,mountport = 908 ,mountproto = udp,local_lock = none,addr = 10 .1.1.138 ) 10 .1.1.138:/mnt/ssd-mirror/ssd-pool on /mnt/pve/ssd-pool type nfs ( rw,relatime,vers = 3 ,rsize = 131072 ,wsize = 131072 ,namlen = 255 ,hard,proto = tcp,timeo = 600 ,retrans = 2 ,sec = sys,mountaddr = 10 .1.1.138,mountvers = 3 ,mountport = 908 ,mountproto = udp,local_lock = none,addr = 10 .1.1.138 ) umount -f -l /mnt/pve/big-dick-pool umount -f -l /mnt/pve/ssd-pool","title":"nfs mount error nfs create storage failed: cfs-lock 'file-storage_cfg' error: got lock request timeout (500)"},{"location":"Homelab/Proxmox-Notes/#nfs-mounts","text":"/mnt/ssd-mirror/ssd-pool /mnt/ssd-mirror/ssd-pool","title":"nfs mounts"},{"location":"Homelab/Proxmox-Notes/#opnsense","text":"","title":"opnsense"},{"location":"Homelab/Proxmox-Notes/#setting-up-opnsense-on-pve","text":"https://docs.netgate.com/pfsense/en/latest/recipes/virtualize-proxmox-ve.html#virtualizing-with-proxmox-ve give opnsense two bridged nics that are separate from what proxmox is using i used vmbr1 (eno1) and vmbr0 (eno2)","title":"setting up opnsense on pve"},{"location":"Homelab/Proxmox-Notes/#disk-testing","text":"nfs share fio Disk Speed Tests (Mixed R/W 50/50): --------------------------------- Block Size | 4k (IOPS) | 64k (IOPS) ------ | --- ---- | ---- ---- Read | 7.25 MB/s (1.8k) | 94.72 MB/s (1.4k) Write | 7.27 MB/s (1.8k) | 95.22 MB/s (1.4k) Total | 14.52 MB/s (3.6k) | 189.95 MB/s (2.9k) | | Block Size | 512k (IOPS) | 1m (IOPS) ------ | --- ---- | ---- ---- Read | 80.93 MB/s (158) | 100.83 MB/s (98) Write | 85.23 MB/s (166) | 107.54 MB/s (105) Total | 166.17 MB/s (324) | 208.38 MB/s (203) local fio Disk Speed Tests (Mixed R/W 50/50): --------------------------------- Block Size | 4k (IOPS) | 64k (IOPS) ------ | --- ---- | ---- ---- Read | 45.77 MB/s (11.4k) | 478.09 MB/s (7.4k) Write | 45.86 MB/s (11.4k) | 480.60 MB/s (7.5k) Total | 91.63 MB/s (22.9k) | 958.69 MB/s (14.9k) | | Block Size | 512k (IOPS) | 1m (IOPS) ------ | --- ---- | ---- ---- Read | 1.88 GB/s (3.6k) | 2.51 GB/s (2.4k) Write | 1.98 GB/s (3.8k) | 2.67 GB/s (2.6k) Total | 3.87 GB/s (7.5k) | 5.19 GB/s (5.0k)","title":"disk testing"},{"location":"Tech/Azure-AZ-900/","text":"Exam Objectives AZ-900 Azure Fundamentals Cloud Service Models IaaS Actual servers being provided by Azure Scaling is fast Only pay for what you use No ownership of hardware VMs, networks, building PaaS Includes infrastructure Middleware Supports the complete web app lifecycle Avoids software license hell SaaS Includes IaaS and PaaS Provides a managed service Gmail, stripe, quickbooks Pay an access fee to use No maintenance and latest features Serverless You don\u2019t manage any servers Azure Functions Azure Marketplace Apps, VMs, templates, services Cloud Architect Models Private - Azure on your own hardware Services within the cloud are only offered to select users Complete control of infra Benefits of public cloud Better security and privacy Organizations IT is responsible for the cloud, not MS Public No purchase of HW Low monthly fees Accessed from anywhere Hybrid Private + Public Avoids disruptions and outages Regulatory Azure Architecture Regions and Availability Zones Regions Region is a set of datacenters deployed within a latency defined perimeter and connected through a dedicated regional low-latency network Each region has more than 1 datacenter How to choose a region Location - close to users for low latency Features - no all features are available in all regions Pricing - pricing varies region per region Choose what is most important Each region is paired with another region in the same geographic location If a primary region has an outage, you can failover to the secondary region Only one region in a pair is updated at a time Some services use paired regions for replication Availability Zones Each AZ is a physical location within a region Each zone has its own power, cooling, and networking Each region has a minimum of 3 zones Resource Groups - container that holds other resources Everything in Azure is inside a resource group Each resource can only exist in 1 resource group You can add or remove resources to any resource group You can move a resource from one resource group to another Resources from multiple regions can be in one resource group You can give users access to a resource group and everything in it Resources can interact with outer resources in different resource groups A resource group has a location, or region, as it stores metadata about the resources in it Azure Resource Manager (ARM) Manages everything with creating or deleting resources You can deploy manage and monitor resources as a group Deploying resources will always result in the same results Define dependencies between resources to make sure they work Built in access control Tag resources to ID them for future scenarios Use tagging to stay on top of billing Creating Azure Resources Can be done in Azure Portal, Powershell, or AzureCLI Compute VMs - virtualized HW that you control - priced per hour Scale Sets - sets of identical VMs that get created and deleted automatically App Services - managed platform for you to host your applications ACI - Azure Container Instances - hosts and runs your containers Kubernetes - Orchestration of container images and applications CLUSTERS AND PODS Windows Virtual Desktop - virtual desktop in the cloud Functions - serverless compute, code that does one function Scale Sets Lets you create and manage a group of identical, load balanced VMs Auto scaling and scheduled scaling of resources No extra cost for HAVING scaling, just for the resources used when scaling is necessary A baseline VM is used as the template for the scaled ones App Services Fully managed platform Webapps Webapps for containers - deploy and run containerized applications in Azure API App - expose and connect your data backend Other applications connect programmatically Azure Container Instances Self contained applications with all of the dependencies Less overhead than VMs More portable, can be deployed to multiple hardware and OS platforms Scaling and patching is simpler ACI - Primary Azure service for running containers User containerized applications to process data on demand by creating container image when you need it Works with Azure portal, Azure cli, and powershell Azure K8s Services Open source container orchestration system for automating application deployment, scaling, and management Replicate container architectures Standard Azure services included Global reach Azure Container Registry (ACR) Keeps track of current container images Manages files and artifacts for containers Feeds container images to ACI and AKS Uses Azure identity and security features Windows Virtual Desktop 100% virtualized Windows 10 desktop Multiple users can use the same VM instance Access anywhere Secure storage of company data in Azure Functions - Serverless Single function of compute Called or invoked by a standard web address Runs once and stops Only runs when needed, saving money If function fails, doesn't affect other services App services are attached to an App Service Plan","title":"Azure AZ 900"},{"location":"Tech/Azure-AZ-900/#az-900-azure-fundamentals","text":"","title":"AZ-900 Azure Fundamentals"},{"location":"Tech/Azure-AZ-900/#cloud-service-models","text":"IaaS Actual servers being provided by Azure Scaling is fast Only pay for what you use No ownership of hardware VMs, networks, building PaaS Includes infrastructure Middleware Supports the complete web app lifecycle Avoids software license hell SaaS Includes IaaS and PaaS Provides a managed service Gmail, stripe, quickbooks Pay an access fee to use No maintenance and latest features Serverless You don\u2019t manage any servers Azure Functions","title":"Cloud Service Models"},{"location":"Tech/Azure-AZ-900/#azure-marketplace","text":"Apps, VMs, templates, services","title":"Azure Marketplace"},{"location":"Tech/Azure-AZ-900/#cloud-architect-models","text":"Private - Azure on your own hardware Services within the cloud are only offered to select users Complete control of infra Benefits of public cloud Better security and privacy Organizations IT is responsible for the cloud, not MS Public No purchase of HW Low monthly fees Accessed from anywhere Hybrid Private + Public Avoids disruptions and outages Regulatory","title":"Cloud Architect Models"},{"location":"Tech/Azure-AZ-900/#azure-architecture","text":"","title":"Azure Architecture"},{"location":"Tech/Azure-AZ-900/#regions-and-availability-zones","text":"Regions Region is a set of datacenters deployed within a latency defined perimeter and connected through a dedicated regional low-latency network Each region has more than 1 datacenter How to choose a region Location - close to users for low latency Features - no all features are available in all regions Pricing - pricing varies region per region Choose what is most important Each region is paired with another region in the same geographic location If a primary region has an outage, you can failover to the secondary region Only one region in a pair is updated at a time Some services use paired regions for replication Availability Zones Each AZ is a physical location within a region Each zone has its own power, cooling, and networking Each region has a minimum of 3 zones Resource Groups - container that holds other resources Everything in Azure is inside a resource group Each resource can only exist in 1 resource group You can add or remove resources to any resource group You can move a resource from one resource group to another Resources from multiple regions can be in one resource group You can give users access to a resource group and everything in it Resources can interact with outer resources in different resource groups A resource group has a location, or region, as it stores metadata about the resources in it Azure Resource Manager (ARM) Manages everything with creating or deleting resources You can deploy manage and monitor resources as a group Deploying resources will always result in the same results Define dependencies between resources to make sure they work Built in access control Tag resources to ID them for future scenarios Use tagging to stay on top of billing Creating Azure Resources Can be done in Azure Portal, Powershell, or AzureCLI","title":"Regions and Availability Zones"},{"location":"Tech/Azure-AZ-900/#compute","text":"VMs - virtualized HW that you control - priced per hour Scale Sets - sets of identical VMs that get created and deleted automatically App Services - managed platform for you to host your applications ACI - Azure Container Instances - hosts and runs your containers Kubernetes - Orchestration of container images and applications CLUSTERS AND PODS Windows Virtual Desktop - virtual desktop in the cloud Functions - serverless compute, code that does one function Scale Sets Lets you create and manage a group of identical, load balanced VMs Auto scaling and scheduled scaling of resources No extra cost for HAVING scaling, just for the resources used when scaling is necessary A baseline VM is used as the template for the scaled ones App Services Fully managed platform Webapps Webapps for containers - deploy and run containerized applications in Azure API App - expose and connect your data backend Other applications connect programmatically Azure Container Instances Self contained applications with all of the dependencies Less overhead than VMs More portable, can be deployed to multiple hardware and OS platforms Scaling and patching is simpler ACI - Primary Azure service for running containers User containerized applications to process data on demand by creating container image when you need it Works with Azure portal, Azure cli, and powershell Azure K8s Services Open source container orchestration system for automating application deployment, scaling, and management Replicate container architectures Standard Azure services included Global reach Azure Container Registry (ACR) Keeps track of current container images Manages files and artifacts for containers Feeds container images to ACI and AKS Uses Azure identity and security features Windows Virtual Desktop 100% virtualized Windows 10 desktop Multiple users can use the same VM instance Access anywhere Secure storage of company data in Azure Functions - Serverless Single function of compute Called or invoked by a standard web address Runs once and stops Only runs when needed, saving money If function fails, doesn't affect other services App services are attached to an App Service Plan","title":"Compute"},{"location":"Tech/Links/","text":"Links to cool things/ideas learning https://github.com/Artemmkin/infrastructure-as-code-tutorial https://github.com/trekhleb/learn-python monitoring https://github.com/Mbarmem/Grafana.Dashboar https://healthchecks.io https://www.atlassian.com/software/statuspage containers https://tech.davidfield.co.uk/from-zero-to-code-moving-from-docker-to-kubernetes https://blog.alexellis.io/bare-metal-kubernetes-with-k3s automation https://github.com/ansible/awx https://cyanlab.io/automating-ubuntu-vm-installations https://github.com/hashicorp/terraform-provider-vsphere security stuff https://www.bastillion.io https://smallstep.com/blog/use-ssh-certificates https://www.fail2ban.org/wiki/index.php/Main_Page vpn stuff https://github.com/mjtechguy/wireguard-site-to-site https://hub.docker.com/r/linuxserver/wireguard misc https://mnx.io/blog/a-proper-server-naming-scheme https://github.com/localstack/localstack https://github.com/jc21/nginx-proxy-manager https://temp.sh https://transfer.sh/ https://github.com/mmeyer725/sshmenu","title":"Links to cool things/ideas"},{"location":"Tech/Links/#links-to-cool-thingsideas","text":"","title":"Links to cool things/ideas"},{"location":"Tech/Links/#learning","text":"https://github.com/Artemmkin/infrastructure-as-code-tutorial https://github.com/trekhleb/learn-python","title":"learning"},{"location":"Tech/Links/#monitoring","text":"https://github.com/Mbarmem/Grafana.Dashboar https://healthchecks.io https://www.atlassian.com/software/statuspage","title":"monitoring"},{"location":"Tech/Links/#containers","text":"https://tech.davidfield.co.uk/from-zero-to-code-moving-from-docker-to-kubernetes https://blog.alexellis.io/bare-metal-kubernetes-with-k3s","title":"containers"},{"location":"Tech/Links/#automation","text":"https://github.com/ansible/awx https://cyanlab.io/automating-ubuntu-vm-installations https://github.com/hashicorp/terraform-provider-vsphere","title":"automation"},{"location":"Tech/Links/#security-stuff","text":"https://www.bastillion.io https://smallstep.com/blog/use-ssh-certificates https://www.fail2ban.org/wiki/index.php/Main_Page","title":"security stuff"},{"location":"Tech/Links/#vpn-stuff","text":"https://github.com/mjtechguy/wireguard-site-to-site https://hub.docker.com/r/linuxserver/wireguard","title":"vpn stuff"},{"location":"Tech/Links/#misc","text":"https://mnx.io/blog/a-proper-server-naming-scheme https://github.com/localstack/localstack https://github.com/jc21/nginx-proxy-manager https://temp.sh https://transfer.sh/ https://github.com/mmeyer725/sshmenu","title":"misc"},{"location":"Tech/RHCSA/","text":"Red Hat Certified System Administrator Exam Objectives Reading Man Pages [] - optional __ - required ... - multiple files Input and Output Redirection > - redirect and overwrite >> - appends file 2> - redirect stderr to something and hide from stdout 2 represents error 2>&1 - redirects stderr to stdout can be used as input with | /dev/null - redirect here to dump into nothingness head - first 10 lines to stdout ex. head messages - first 10 lines of messages file tail -f - continue appending as it's added to the file Using grep and regex to Analyze Text grep '^#' /etc/ssh/sshd_config ^ - means to search for lines that start with # searches that file and looks for lines that start with # grep -i 'rsaauth' /etc/ssh/sshd_config -i - ignore case finds all occurances of rsaauth, ignoring case grep -v '^#' file -v - inverse searches for every line that DOESN'T start with # grep 'world$' file $ - line ends with searches for all lines that end with world grep [Ll]inuxacademy file [] - allows for multiple arguments searches for lines that start with capital and lowercase L grep '[^linux] file [^linux] - when the carat is in [] it means to negate the following text searches for everthing that does not include an l, i, n, u, or x. grep -E '(a)+' file -E runs egrep searches for the occurance of 'a' as many times as it appears grep 'l...x' file 'l...x' - ... symbolizes any character searches for a pattern that starts with l and ends with x with 3 characters inbetween them basic and extended regular expressions ? + { [ | () . * ^ $ ? - preceeding item is optional and matched once at most + - preceeding item is matched one or more times Accessing Remote Systems Using SSH ssh config - /etc/ssh_config PermitRootLogin - allows the root user to login via ssh - commented out by default best practice to disable because an attacker would need to compromise regular user to login, then gain root permissions always restart ssh service - systemctl restart sshd issue commands to remote server ssh user@hostname ls - this will run ls on user's home directory scp - file transfer that uses ssh protocol scp file.txt user@hostname:~/dir this will transfer file.txt to the remote server and put it in user's ~/dir directory sftp this is just ssh with get and put commands Login and Switch Users in Multiuser Targets multiuser target - multiple users on same system su - switch user to interactive shell su - , su -l , su --login - switch user to login shell interactive shell v. login shell - login shell will load custom configs and profiles .bash_logout - when user logs out, everything in this file is executed bash_profile - contains customazions for your login shell, PATH, aliases, etc bashrc - contains customizations for interactive shell /etc/profile - global bash_profile Archive, Compress, Unpack, and Uncompress Files using tar , star , gzip , and bzip2 tar - allows for creation and compression of archives gzip filename - zips a file gunzip or gzip -d - unzips file compress directory and contents need to create an archive first tar -cvf archive.tar dir1\\ hello1 hello2 c - create archive v - verbosly f - specify name of archive gzip archive.tar compress directory and contents w/ only tar tar -cvzf archive.tar.gz dir1/ hello1 hello2 z - run through gzip list files within an archive tar -tf archive.tar compress directory and contents w/ tar and bzip tar -cvjf archive.tar.gz dir1/ hello1 hello2 j - run through bzip extract a tar archive tar -xvf archive.tar x - extract extract tar .gz tar -xzvf archive.tar.gz if you extract an archive into a directory that contains files of the same name, the extracted files will overwrite what's in the directory show differences between archived files and files in a directory tar -dvf archive.tar.gz d - shows difference between archive and current directory view compression information of a gzip archive gzip -l archive.gz star - used for large datasets, making sure to not overwrite updated files can use the find command to extract specific files from an archive creating an archive with star star -c -f=archive.tar dir1\\ hello1 hello2 c - create archive f - filename list contents of archive with star star -t -f=archive.tar t - lists files in archive extract archive with star star -x -f=archive.tar extract single file named hello1 from archive star -x -f=archive.tar hello1 Create and Edit Text Files vim is the only option here, nano is for virgins cw - change word cc - remove line and enter insert mode R - replace mode - writes over existing text replace first occurance of line with word :%s/line/word replace all occurances of line with word :%s/line/word/g - g is global ls inside current directory from within vim :! ls ls /etc/ from within vim :! ls /etc/ Create, Delete, Copy, and Move Files and Directories create directories recursively mkdir -p new-dir/dir1/dir2 p - create parent directories rmdir - removes directories but not recursively Create Hard Links and Soft Links ln - creates symbolic and hard links by default will create a hard link soft links ln -s /etc/motd motd creates a soft link from /etc/motd to motd in current directory s - soft link soft links will be broken if source target is moved/removed symbolic links can link across filesystems soft links are similar to shortcuts permission are inheritied from source file, symlink permissions do not matter hard links link directly to a specific inode location on a filesystem cannot link across filesystems when permissions are changed on one hard link target it's applied to the other as well List, Set, and Change Standard UGO/RWX Permissions first bit is file/dir/symlink d is dir is file l is symlink after that groups of 3 are used first 3 are owner second 3 are group last 3 are other, everyone else on the system rwx - read, write, execute x - allows for execution of scripts permissions are changed with chmod octal or symbolic notation chmod u+x - gives user execute permissions chmod u-x - removes execute permissions from user chmod g+x - gives group execute permissions chmod u+wrx = gives user rwx permissions add a group groupadd finance not in roots path, launched from /usr/sbin/groupadd list groups getent group cat /etc/group change owner (user and group) of an object chown user:group object change only group of an object chown :group object to navigate into a directory you need execute privileges add a secondary group to a user usermod -G object user G - secondary group user will need to logout for changes to take effect grant a group write permissions for an object chmod g+w -R object g+w - grant write to group R - recursively log user into another group as primary group newgrp groupname only allow directories to have execute permissions chmod ug+X -R object X - this changes it so only directories have execute this is good if you have scripts located in directories but don't want to mass allow the execution of them grant permissions for everyone (user, group, and other) chmod a+r object a - grants to it user, group, and other octal permissions allows for the use of numeric notation to set permissions chmod 777 first character is owner second character is group owner third character is other 777 results in rwx for everyone the bits add up to 7 read = 4 write = 2 execute = 1 chmod 440 -R directory R - recursive setuid and setgid setgid is a permission bit when you are to exectute or open a file a new process is forked as the user who is executing the file setgid allows you to execute a file with the permissions of whoever owns the file, not who is executing it sticky bit represents setuid, shown as s (user) and S (group) in ls permissions essentially, setuid means execute this file with permissions of the owner of the file, not as the user executing the file setgid means execute with permissions of the group that owns it chmod u+s file - will run with same permissions as user who owns file chmod g+s file - will run with same permissions as group who owns the file chmod 4500 file - 4 represensts setuid on the user chmod 2500 file - 2 represents setgid on group chmod 6500 file - 6 will setuid and setgid for both user and group sticky bit - prevents unauthorized users from deleting or renaming a file chmod +t file chmod 1777 file 1 - set sticky bit chmod 7777 file setuid, setgid, and stickybit (just add them together) List, Set, and Change Standard UGO/RWX Permissions: umask umask - stands for user mask, allows for the setting of default permissions show default umask permissions with umask umask sets permissions for current session, logout clears them deafult is 0022 2 sets of umask permissions - privileged users and non-privileged default for a file is 666 default for a directory is 777 umask will never give execute permissions on a file - it will for a directory though Locate, Read, and Use System Documentation with man , info , and /usr/share/doc documentation can be from man page, from --help , from info , from /usr/share/doc, or within the rpm man 5 passwd - opens page 5 of man page apropos passwd - searches through all man pages, has to be cached though mandb - indexes everything in /usr/share/mani info - alternative to man pages searches /usr/share/info from within info hit ? to see navigation shortcuts info --apropos=tee - searches info for tee sometimes template config files will live here as well locate passwd searches cached database of entire system for anything related to passwd updatedb - updates locate cache if locate isn't installed, install the mlocate package which passwd - shows absolute path of program whatis passwd shows man pages for program - searches descriptions whereis - locates binary and source files for program rpm -qd packagename queries document files for the specified program Finding Files with locate and find locate - searches cached files in a database, db is updated by cron updatedb - updates locate cache find - much more powerful and can be complicated find /etc -name motd - searches /etc for ANYTHING with the name of motd find /etc -user root - finds everything in /etc owned by root find / -mtime -3 - finds everything in / that have been modified in last 3 days find / -mtime +3 - finds everything in / that have been modified in a time greater than the last 3 days find / -uid 1002 - finds everything in / owned by user 1002 find / -user jeff -type f finds all FILES owned by jeff find / -user jeff -type f -exec cat {} \\; - finds all FILES owned by jeff and cats them {} means perform the exec on each file \\; ends command find / -user jeff -type f -exec cp {} /home/mary \\; - finds all FILES owned by jeff and copies them to marys home directory find /home/ -user jeff -type f exec rm {} \\. - finds all FILES owned by jeff and removes each file Boot, Reboot, and Shutdown a System newer rhel systems are using systemd as init system init 0 - runlevel 0, shutsdown the system init 6 - runlevel 6, restarts the system init is the deprecated way of doing this reboot - calls systemctl reboot shutdown -r - reboot -p - powers off shutdown -r +5 System going down for reboot - reboots system in 5 minutes with message displayed to users shutdown -c - cancels reboot shutdown -r 00:00 - schedules reboot for 12AM (24hr time) when system is being shutdown its having its target changed targets replace runlevels in systemd /usr/lib/systemd/system - default targets physically poweroff a system systemctl poweroff poweroff shutdown -p shutdown is the proper way to handle power management and reboots Boot Systems into Different Targets Manually systemd has parallel bootup - can start multiple services at the same time systemd unit config files are called targets list available targets systemctl list-units --type=target list different target types systemctl -t help systemd unit config files target config files unit config files are located in /usr/lib/systemd/system instead of writing startup scripts you write systemd unit services WantedBy - this is where you specify that your service is a dependency of a certain target systemctl list-dependencies multi-user.target - list dependencies of multi-user target systemctl get-default - lists current target targets multi-user.target - multiple users can be logged into the system, most likely terminal graphical.target - GUI emergency.target - boots into root terminal with fs mounted read only rescue.target - launches single user environment with minimal resources to troubleshoot and resuce system reboot.target AllowIsolate - means move system into this target and load the dependencies systemctl isolate multi-user.target - moves into multi-user target systemctl set-default multi-user.target - sets default target to multi-user default target is just symlink to specific target file interrupt the boot process and enter emergency or rescue interrupt at grub and edit linux16 kernel line add systemd.unit=rescue.target to the end continue boot Interrupt the Boot Process to Gain Access to a System Can be used to reset root password edit linux16 line in GRUB add rd.break launches into initramfs Misc. Notes LVM looking into changing root pw runlevels have been deprecated with systemd - replaced with targets awk tee stat file - shows status of a file umask - learn this, seems hard yum group list - lists package groups look up inodes SUDO - Substitute User and DO look into setuid and setgid history \\ - allows searching through history touch {file1,file2,file3} - create multiple files with {} systemctl get-default - returns a target by deafult RHEL7 aliases rm to rm -i to force deletion prompt","title":"RHCSA"},{"location":"Tech/RHCSA/#red-hat-certified-system-administrator","text":"Exam Objectives","title":"Red Hat Certified System Administrator"},{"location":"Tech/RHCSA/#reading-man-pages","text":"[] - optional __ - required ... - multiple files","title":"Reading Man Pages"},{"location":"Tech/RHCSA/#input-and-output-redirection","text":"> - redirect and overwrite >> - appends file 2> - redirect stderr to something and hide from stdout 2 represents error 2>&1 - redirects stderr to stdout can be used as input with | /dev/null - redirect here to dump into nothingness head - first 10 lines to stdout ex. head messages - first 10 lines of messages file tail -f - continue appending as it's added to the file","title":"Input and Output Redirection"},{"location":"Tech/RHCSA/#using-grep-and-regex-to-analyze-text","text":"grep '^#' /etc/ssh/sshd_config ^ - means to search for lines that start with # searches that file and looks for lines that start with # grep -i 'rsaauth' /etc/ssh/sshd_config -i - ignore case finds all occurances of rsaauth, ignoring case grep -v '^#' file -v - inverse searches for every line that DOESN'T start with # grep 'world$' file $ - line ends with searches for all lines that end with world grep [Ll]inuxacademy file [] - allows for multiple arguments searches for lines that start with capital and lowercase L grep '[^linux] file [^linux] - when the carat is in [] it means to negate the following text searches for everthing that does not include an l, i, n, u, or x. grep -E '(a)+' file -E runs egrep searches for the occurance of 'a' as many times as it appears grep 'l...x' file 'l...x' - ... symbolizes any character searches for a pattern that starts with l and ends with x with 3 characters inbetween them basic and extended regular expressions ? + { [ | () . * ^ $ ? - preceeding item is optional and matched once at most + - preceeding item is matched one or more times","title":"Using grep and regex to Analyze Text"},{"location":"Tech/RHCSA/#accessing-remote-systems-using-ssh","text":"ssh config - /etc/ssh_config PermitRootLogin - allows the root user to login via ssh - commented out by default best practice to disable because an attacker would need to compromise regular user to login, then gain root permissions always restart ssh service - systemctl restart sshd issue commands to remote server ssh user@hostname ls - this will run ls on user's home directory scp - file transfer that uses ssh protocol scp file.txt user@hostname:~/dir this will transfer file.txt to the remote server and put it in user's ~/dir directory sftp this is just ssh with get and put commands","title":"Accessing Remote Systems Using SSH"},{"location":"Tech/RHCSA/#login-and-switch-users-in-multiuser-targets","text":"multiuser target - multiple users on same system su - switch user to interactive shell su - , su -l , su --login - switch user to login shell interactive shell v. login shell - login shell will load custom configs and profiles .bash_logout - when user logs out, everything in this file is executed bash_profile - contains customazions for your login shell, PATH, aliases, etc bashrc - contains customizations for interactive shell /etc/profile - global bash_profile","title":"Login and Switch Users in Multiuser Targets"},{"location":"Tech/RHCSA/#archive-compress-unpack-and-uncompress-files-using-tar-star-gzip-and-bzip2","text":"tar - allows for creation and compression of archives gzip filename - zips a file gunzip or gzip -d - unzips file compress directory and contents need to create an archive first tar -cvf archive.tar dir1\\ hello1 hello2 c - create archive v - verbosly f - specify name of archive gzip archive.tar compress directory and contents w/ only tar tar -cvzf archive.tar.gz dir1/ hello1 hello2 z - run through gzip list files within an archive tar -tf archive.tar compress directory and contents w/ tar and bzip tar -cvjf archive.tar.gz dir1/ hello1 hello2 j - run through bzip extract a tar archive tar -xvf archive.tar x - extract extract tar .gz tar -xzvf archive.tar.gz if you extract an archive into a directory that contains files of the same name, the extracted files will overwrite what's in the directory show differences between archived files and files in a directory tar -dvf archive.tar.gz d - shows difference between archive and current directory view compression information of a gzip archive gzip -l archive.gz star - used for large datasets, making sure to not overwrite updated files can use the find command to extract specific files from an archive creating an archive with star star -c -f=archive.tar dir1\\ hello1 hello2 c - create archive f - filename list contents of archive with star star -t -f=archive.tar t - lists files in archive extract archive with star star -x -f=archive.tar extract single file named hello1 from archive star -x -f=archive.tar hello1","title":"Archive, Compress, Unpack, and Uncompress Files using tar, star, gzip, and bzip2"},{"location":"Tech/RHCSA/#create-and-edit-text-files","text":"vim is the only option here, nano is for virgins cw - change word cc - remove line and enter insert mode R - replace mode - writes over existing text replace first occurance of line with word :%s/line/word replace all occurances of line with word :%s/line/word/g - g is global ls inside current directory from within vim :! ls ls /etc/ from within vim :! ls /etc/","title":"Create and Edit Text Files"},{"location":"Tech/RHCSA/#create-delete-copy-and-move-files-and-directories","text":"create directories recursively mkdir -p new-dir/dir1/dir2 p - create parent directories rmdir - removes directories but not recursively","title":"Create, Delete, Copy, and Move Files and Directories"},{"location":"Tech/RHCSA/#create-hard-links-and-soft-links","text":"ln - creates symbolic and hard links by default will create a hard link soft links ln -s /etc/motd motd creates a soft link from /etc/motd to motd in current directory s - soft link soft links will be broken if source target is moved/removed symbolic links can link across filesystems soft links are similar to shortcuts permission are inheritied from source file, symlink permissions do not matter hard links link directly to a specific inode location on a filesystem cannot link across filesystems when permissions are changed on one hard link target it's applied to the other as well","title":"Create Hard Links and Soft Links"},{"location":"Tech/RHCSA/#list-set-and-change-standard-ugorwx-permissions","text":"first bit is file/dir/symlink d is dir is file l is symlink after that groups of 3 are used first 3 are owner second 3 are group last 3 are other, everyone else on the system rwx - read, write, execute x - allows for execution of scripts permissions are changed with chmod octal or symbolic notation chmod u+x - gives user execute permissions chmod u-x - removes execute permissions from user chmod g+x - gives group execute permissions chmod u+wrx = gives user rwx permissions add a group groupadd finance not in roots path, launched from /usr/sbin/groupadd list groups getent group cat /etc/group change owner (user and group) of an object chown user:group object change only group of an object chown :group object to navigate into a directory you need execute privileges add a secondary group to a user usermod -G object user G - secondary group user will need to logout for changes to take effect grant a group write permissions for an object chmod g+w -R object g+w - grant write to group R - recursively log user into another group as primary group newgrp groupname only allow directories to have execute permissions chmod ug+X -R object X - this changes it so only directories have execute this is good if you have scripts located in directories but don't want to mass allow the execution of them grant permissions for everyone (user, group, and other) chmod a+r object a - grants to it user, group, and other octal permissions allows for the use of numeric notation to set permissions chmod 777 first character is owner second character is group owner third character is other 777 results in rwx for everyone the bits add up to 7 read = 4 write = 2 execute = 1 chmod 440 -R directory R - recursive setuid and setgid setgid is a permission bit when you are to exectute or open a file a new process is forked as the user who is executing the file setgid allows you to execute a file with the permissions of whoever owns the file, not who is executing it sticky bit represents setuid, shown as s (user) and S (group) in ls permissions essentially, setuid means execute this file with permissions of the owner of the file, not as the user executing the file setgid means execute with permissions of the group that owns it chmod u+s file - will run with same permissions as user who owns file chmod g+s file - will run with same permissions as group who owns the file chmod 4500 file - 4 represensts setuid on the user chmod 2500 file - 2 represents setgid on group chmod 6500 file - 6 will setuid and setgid for both user and group sticky bit - prevents unauthorized users from deleting or renaming a file chmod +t file chmod 1777 file 1 - set sticky bit chmod 7777 file setuid, setgid, and stickybit (just add them together)","title":"List, Set, and Change Standard UGO/RWX Permissions"},{"location":"Tech/RHCSA/#list-set-and-change-standard-ugorwx-permissions-umask","text":"umask - stands for user mask, allows for the setting of default permissions show default umask permissions with umask umask sets permissions for current session, logout clears them deafult is 0022 2 sets of umask permissions - privileged users and non-privileged default for a file is 666 default for a directory is 777 umask will never give execute permissions on a file - it will for a directory though","title":"List, Set, and Change Standard UGO/RWX Permissions: umask"},{"location":"Tech/RHCSA/#locate-read-and-use-system-documentation-with-man-info-and-usrsharedoc","text":"documentation can be from man page, from --help , from info , from /usr/share/doc, or within the rpm man 5 passwd - opens page 5 of man page apropos passwd - searches through all man pages, has to be cached though mandb - indexes everything in /usr/share/mani info - alternative to man pages searches /usr/share/info from within info hit ? to see navigation shortcuts info --apropos=tee - searches info for tee sometimes template config files will live here as well locate passwd searches cached database of entire system for anything related to passwd updatedb - updates locate cache if locate isn't installed, install the mlocate package which passwd - shows absolute path of program whatis passwd shows man pages for program - searches descriptions whereis - locates binary and source files for program rpm -qd packagename queries document files for the specified program","title":"Locate, Read, and Use System Documentation with man, info, and /usr/share/doc"},{"location":"Tech/RHCSA/#finding-files-with-locate-and-find","text":"locate - searches cached files in a database, db is updated by cron updatedb - updates locate cache find - much more powerful and can be complicated find /etc -name motd - searches /etc for ANYTHING with the name of motd find /etc -user root - finds everything in /etc owned by root find / -mtime -3 - finds everything in / that have been modified in last 3 days find / -mtime +3 - finds everything in / that have been modified in a time greater than the last 3 days find / -uid 1002 - finds everything in / owned by user 1002 find / -user jeff -type f finds all FILES owned by jeff find / -user jeff -type f -exec cat {} \\; - finds all FILES owned by jeff and cats them {} means perform the exec on each file \\; ends command find / -user jeff -type f -exec cp {} /home/mary \\; - finds all FILES owned by jeff and copies them to marys home directory find /home/ -user jeff -type f exec rm {} \\. - finds all FILES owned by jeff and removes each file","title":"Finding Files with locate and find"},{"location":"Tech/RHCSA/#boot-reboot-and-shutdown-a-system","text":"newer rhel systems are using systemd as init system init 0 - runlevel 0, shutsdown the system init 6 - runlevel 6, restarts the system init is the deprecated way of doing this reboot - calls systemctl reboot shutdown -r - reboot -p - powers off shutdown -r +5 System going down for reboot - reboots system in 5 minutes with message displayed to users shutdown -c - cancels reboot shutdown -r 00:00 - schedules reboot for 12AM (24hr time) when system is being shutdown its having its target changed targets replace runlevels in systemd /usr/lib/systemd/system - default targets physically poweroff a system systemctl poweroff poweroff shutdown -p shutdown is the proper way to handle power management and reboots","title":"Boot, Reboot, and Shutdown a System"},{"location":"Tech/RHCSA/#boot-systems-into-different-targets-manually","text":"systemd has parallel bootup - can start multiple services at the same time systemd unit config files are called targets list available targets systemctl list-units --type=target list different target types systemctl -t help systemd unit config files target config files unit config files are located in /usr/lib/systemd/system instead of writing startup scripts you write systemd unit services WantedBy - this is where you specify that your service is a dependency of a certain target systemctl list-dependencies multi-user.target - list dependencies of multi-user target systemctl get-default - lists current target targets multi-user.target - multiple users can be logged into the system, most likely terminal graphical.target - GUI emergency.target - boots into root terminal with fs mounted read only rescue.target - launches single user environment with minimal resources to troubleshoot and resuce system reboot.target AllowIsolate - means move system into this target and load the dependencies systemctl isolate multi-user.target - moves into multi-user target systemctl set-default multi-user.target - sets default target to multi-user default target is just symlink to specific target file interrupt the boot process and enter emergency or rescue interrupt at grub and edit linux16 kernel line add systemd.unit=rescue.target to the end continue boot","title":"Boot Systems into Different Targets Manually"},{"location":"Tech/RHCSA/#interrupt-the-boot-process-to-gain-access-to-a-system","text":"Can be used to reset root password edit linux16 line in GRUB add rd.break launches into initramfs","title":"Interrupt the Boot Process to Gain Access to a System"},{"location":"Tech/RHCSA/#misc-notes","text":"LVM looking into changing root pw runlevels have been deprecated with systemd - replaced with targets awk tee stat file - shows status of a file umask - learn this, seems hard yum group list - lists package groups look up inodes SUDO - Substitute User and DO look into setuid and setgid history \\ - allows searching through history touch {file1,file2,file3} - create multiple files with {} systemctl get-default - returns a target by deafult RHEL7 aliases rm to rm -i to force deletion prompt","title":"Misc. Notes"},{"location":"Tech/arch-linux-install/","text":"Arch Linux Install Guide Create Installation Media Download Arch ISO - https://www.archlinux.org/download/ Make bootable USB dd bs=4M if=/path/to/archlinux.iso of=/dev/sdx status=progress oflag=sync Pre-Installation Boot to installation media Set time with timedatectl set-ntp true Partition disk Identify what disk you're installing to with fdisk -l or lsblk The disk I'm installing to is /dev/sdc - replace this with your disk We will need /boot, /, /home, and swap Drop into fdisk prompt fdisk /dev/sdc Print partitions with p Delete current partitions with d After deleting current partitions, write changes with w Create a new partiton with n - we're going to create our boot partiton first Press enter for the default partition number Press enter for default first sector For the last sector, you will select how large you want the partition to be. I'm choosing +550M here since I'm using an EFI system If you're prompted by a message station that the partition contains a vfat signature, press Y to remove it. Press n again to create a new partition, pressing enter through the default partition number and first sector size This will be the swap partition. I don't really know how useful this is since I have a lot of RAM and never sleep the computer. I'm entering +8G for the last sector size. Next partition is root, follow the prompts again and select a size sufficient for everything you think you will need to install. I'm going with 60G Last partition will be /home, just press enter through the prompts to use the rest of the disk. After that press w to write the changes to the disk. Drop back into the fdisk prompt and press p to check that they're all there. Here is the layout that I'll be using: /dev/sdc1 550M - /boot /dev/sdc2 8G - swap /dev/sdc3 60G - / /dev/sdc4 397.2G - /home Now we need to set the partition type for our EFI boot partition. Press l to list partition types, we'll be using 1 EFI System. Press t to change partition types, select the partition, 1 in my case and press 1 to change it to EFI System. Again, press w to write these changes. Creating Filesystems After partitioning the disks you will need to create the filesystems on those partitions. You will use the mkfs command for that. Here are the commands I used to make the filesystems: mkfs.vfat /dev/sdc1 - EFI Boot has to be vfat mkswap /dev/sdc2 - sets swap swapon /dev/sdc2 - enables swap mkfs.ext4 /dev/sdc3 - ext4 on / mkfs.ext4 /dev/sdc4 - ext4 on /home Mounting Filesystems Mount your root file system at /mnt mount /dev/sdc3 /mnt Make directories to mount /boot and /home mkdir /mnt/home mkdir /mnt/boot All of your file systems are now mounted Installation Install is super easy, just issue the command below pacstrap /mnt base base-devel - this will install the base package group and the base-devel package group Post Install First thing is to configure fstab so your partitions are mounted at boot genfstab -U /mnt >> /mnt/etc/fstab -U mounts by UUID, you can do drive labels with -L if you like. cat /mnt/etc/fstab - verify all of your partitions are there and correct Change root into the installation arch-chroot /mnt Set timezone ln -sf /usr/share/zoneinfo/America/New_York /etc/localtime - This will set the time for US EST hwclock --systohc - generates /etc/localtime Check that the time is correct with date Uncomment en_US.UTF-8 UTF-8 and other needed locales in /etc/locale.gen vi /etc/locale.gen Generate locale with locale-gen Set the LANG variable in /etc/locale.conf vi /etc/locale.conf - this will be a new file add \"LANG=en_US.UTF-8\" without the quotes on the first line Set the hostname in /etc/hostname vi /etc/hostname Edit info in hosts vi /etc/hosts Mine looks like this: 127.0.0.1 localhost ::1 localhost 127.0.0.1 rt-arch.rtynerlabs.io rt-arch Set root password passwd Install and enable a network manager to get DHCP pacman -S networkmanager - there are others, but I use NetworkManager. systemctl enable NetworkManager Install and configure GRUB pacman -S grub pacman -S efibootmgr grub-install --target=x86_64-efi --efi-directory=/mnt --bootloader-id=GRUB grub-mkconfig -o /boot/grub/grub.cfg - creates GRUB config Unmount your drives and reboot exit - Exits chroot environment umount -R /mnt reboot now Post Reboot Create your user and group, and grant sudo permissions groupadd rt useradd -m -g rt -s /bin/bash rt passwd rt edit sudoers file visudo ## User privilege specification ## root ALL=(ALL) ALL rt ALL=(ALL) ALL logout - don't su , it breaks startx in the next section Login with your new user Install graphical environment sudo pacman -S xorg-server xorg-xinit xorg-xrandr sudo pacman -S i3 dmenu - window manager edit ~/.xinirc to start i3 exec i3 sudo pacman -S rxvt-unicode - terminal emulator sudo pacman -S ttf-hack - terminal font sudo pacman -S ttf-dejavu ttf-liberation - fixes firefox fonts sudo pacman -S nvidia - graphics drivers sudo pacman -S pulseaudio alsa-utils - if you want sound reboot - reboot is needed after graphics drivers installation After reboot, login at the tty and type startx Now you are ready to configure your window manager Install Packages & Other Configuration After you're in the graphical environment, you're ready to install anything else you'll need. Some of my go to's are below. sudo pacman -S firefox chromium zsh unzip git htop python python-pip vim wget feh compton rofi tmux ranger w3m youtube-dl zathura zathura-pdf-mupdf pandoc fd bat zsh-syntax-highlighting neofetch irssi nmap ntop tcpdump imagemagick oh-my-zsh sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" - Only curl scripts to bash if you've read the script and trust the source, better to not do this though. git clone https://github.com/denysdovhan/spaceship-prompt.git \"$ZSH_CUSTOM/themes/spaceship-prompt\" ln -s \"$ZSH_CUSTOM/themes/spaceship-prompt/spaceship.zsh-theme\" \"$ZSH_CUSTOM/themes/spaceship.zsh-theme\" yay - AUR helper, allows for software installation from Arch User Repo git clone https://aur.archlinux.org/yay.git cd yay makepkg -si yay polybar - i3 status bar yay ttf-material-icons ttf-weather-icons ttf-font-awesome - fonts for polybar yay discord-canary - this version seems to work better with Arch yay spotify yay tldr - better help yay vim-instant-markdown - browser real time md preview yay insync - Google Drive client yay hangups - Google Hangouts client yay boostnote - GUI mardown editor yay bitwarden-bin - password manager yay taskbook - todo manager Create or copy over ssh keys create new ssh-keygen -t rsa copy ssh keys mkdir ~/.ssh cp $PATH_TO_SSH_KEYS ~/.ssh chmod 700 ~/.ssh chmod 644 ~/.ssh/id_rsa.pub chmod 600 ~/.ssh/id_rsa Create directories mkdir ~/working mkdir ~/projects && cd ~/projects && git init git config --global user.email \"EMAIL\" git config --global user.name \"NAME\" Clone repos cd ~/working && wget https://raw.githubusercontent.com/rtyner/misc-scripts/master/git-clone.sh && chmod u+x git-clone.sh && ./git-clone.sh Symlink dotfiles ln -s /home/rt/projects/dotfiles/zsh/.zshrc /home/rt/.zshrc ln -s /home/rt/projects/dotfiles/vim/.vimrc /home/rt/.vimrc ln -s /home/rt/projects/dotfiles/i3/config /home/rt/.config/i3/config ln -s /home/rt/projects/dotfiles/polybar/config /home/rt/.config/polybar/config ln -s /home/rt/projects/dotfiles/rofi/config /home/rt/.config/rofi/config ln -s /home/rt/projects/dotfiles/xresources/.Xresources /home/rt/.Xresources ln -s /home/rt/projects/dotfiles/xresources/.xinitrc /home/rt/.initrc Setup Vim plugins mkdir -p ~/.vim/autoload ~/.vim/bundle && curl -LSso ~/.vim/autoload/pathogen.vim https://tpo.pe/pathogen.vim cd ~/.vim/bundle && git clone git://github.com/arcticicestudio/nord-vim.git cd ~/.vim/bundle && git clone https://github.com/tpope/vim-fugitive.git && vim -u NONE -c \"helptags vim-fugitive/doc\" -c q git clone https://github.com/itchyny/lightline.vim ~/.vim/bundle/lightline.vim Install Python packages pip install netaddr --user pip install flask --user pip install paramiko --user pip install pywal --user pip install sshmenu --user","title":"Arch linux install"},{"location":"Tech/docker-compose/","text":"Docker Compose Notes https://dockerswarm.rocks/ https://docs.docker.com/engine/swarm/ https://geek-cookbook.funkypenguin.co.nz/ha-docker-swarm/design/ https://www.smarthomebeginner.com/traefik-2-docker-tutorial/ https://www.youtube.com/watch?v=3c-iBn73dDE https://www.youtube.com/c/TechWorldwithNana/videos what is docker swarm clustered node of of docker hosts with distributed manager nodes to provide fault tolerance Hostname IP Description prod-docker-mgr1.rtynerlabs.io 192.168.1.25 docker swarm manager prod-docker-node1.rtynerlabs.io 192.168.1.26 docker swarm node 1 prod-docker-node2.rtynerlabs.io 192.168.1.27 docker swarm node 1 Hostname IP Description do-docker-mgr1 137.184.58.157 docker swarm manager do-docker-node1 143.198.189.109 docker swarm node 1 do-docker-node2 167.99.232.2 docker swarm node 2 docker swarm init --advertise-addr 192.168.1.25 output from docker manager showing that some nodes are now rejected rt@prod-dock-hf01:~$ docker service ps --no-trunc swarmpit_agent ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ```ktu9gbsy1a7gjwzjqwfvzaxij _ swarmpit_agent.hojfizog23pbdyr3iifdbsb2s swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-1 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" 456q110qfrxxxuhgdbe4uc4yt _ swarmpit_agent.hojfizog23pbdyr3iifdbsb2s swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-1 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" s6u35v26dvjqoozq73ykvk736 _ swarmpit_agent.nymh0inei5jhk3fmxo4v59l9x swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-node1 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" gg9h62jjb4a2tde5jim8skn0s _ swarmpit_agent.nymh0inei5jhk3fmxo4v59l9x swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-node1 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" pe0501ao1e3w6plwipjpt5e0r _ swarmpit_agent.ya3ugvz4d9nsk1gcpeo4vhdlg swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-node3 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" lwdywux7by2mckayqhdpzqcmo _ swarmpit_agent.ya3ugvz4d9nsk1gcpeo4vhdlg swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-node3 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" h7rt5dkwxa03u0pqubiwhw3h7 _ swarmpit_agent.zlpebejmbatxvsfkq7clz9990 swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-2 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" qctyh7tieuc8hdbr890o0agw4 _ swarmpit_agent.zlpebejmbatxvsfkq7clz9990 swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-2 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" ```","title":"Docker Compose Notes"},{"location":"Tech/docker-compose/#docker-compose-notes","text":"https://dockerswarm.rocks/ https://docs.docker.com/engine/swarm/ https://geek-cookbook.funkypenguin.co.nz/ha-docker-swarm/design/ https://www.smarthomebeginner.com/traefik-2-docker-tutorial/ https://www.youtube.com/watch?v=3c-iBn73dDE https://www.youtube.com/c/TechWorldwithNana/videos","title":"Docker Compose Notes"},{"location":"Tech/docker-compose/#what-is-docker-swarm","text":"clustered node of of docker hosts with distributed manager nodes to provide fault tolerance Hostname IP Description prod-docker-mgr1.rtynerlabs.io 192.168.1.25 docker swarm manager prod-docker-node1.rtynerlabs.io 192.168.1.26 docker swarm node 1 prod-docker-node2.rtynerlabs.io 192.168.1.27 docker swarm node 1 Hostname IP Description do-docker-mgr1 137.184.58.157 docker swarm manager do-docker-node1 143.198.189.109 docker swarm node 1 do-docker-node2 167.99.232.2 docker swarm node 2 docker swarm init --advertise-addr 192.168.1.25 output from docker manager showing that some nodes are now rejected rt@prod-dock-hf01:~$ docker service ps --no-trunc swarmpit_agent ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ```ktu9gbsy1a7gjwzjqwfvzaxij _ swarmpit_agent.hojfizog23pbdyr3iifdbsb2s swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-1 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" 456q110qfrxxxuhgdbe4uc4yt _ swarmpit_agent.hojfizog23pbdyr3iifdbsb2s swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-1 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" s6u35v26dvjqoozq73ykvk736 _ swarmpit_agent.nymh0inei5jhk3fmxo4v59l9x swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-node1 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" gg9h62jjb4a2tde5jim8skn0s _ swarmpit_agent.nymh0inei5jhk3fmxo4v59l9x swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-node1 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" pe0501ao1e3w6plwipjpt5e0r _ swarmpit_agent.ya3ugvz4d9nsk1gcpeo4vhdlg swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-node3 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" lwdywux7by2mckayqhdpzqcmo _ swarmpit_agent.ya3ugvz4d9nsk1gcpeo4vhdlg swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-node3 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" h7rt5dkwxa03u0pqubiwhw3h7 _ swarmpit_agent.zlpebejmbatxvsfkq7clz9990 swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-2 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" qctyh7tieuc8hdbr890o0agw4 _ swarmpit_agent.zlpebejmbatxvsfkq7clz9990 swarmpit/agent:latest@sha256:f92ba65f7923794d43ebffc88fbd49bfe8cde8db48ca6888ece5747b9ab1375c prod-docker-2 Shutdown Rejected 18 hours ago \"assigned node no longer meets constraints\" ```","title":"what is docker swarm"},{"location":"Tech/pi-hole-blocklist/","text":"PiHole Blocklist clients4.google.com> clients2.google.com s.youtube.com googleapis.l.google.com www.msftncsi.com outlook.office365.com products.office.com c.s-microsoft.com i.s-microsoft.com login.live.com login.microsoftonline.com dl.delivery.mp.microsoft.com geo-prod.do.dsp.mp.microsoft.com displaycatalog.mp.microsoft.com sls.update.microsoft.com.akadns.net fe3.delivery.dsp.mp.microsoft.com.nsatc.net tlu.dl.delivery.mp.microsoft.com msedge.api.cdp.microsoft.com officeclient.microsoft.com itunes.apple.com s.mzstatic.com appleid.apple.com msftncsi.com ipv6.msftncsi.com captive.apple.com gsp1.apple.com www.apple.com www.appleiphonecell.com spclient.wg.spotify.com apresolve.spotify.com api-tv.spotify.com upload.facebook.com creative.ak.fbcdn.net external-lhr0-1.xx.fbcdn.net external-lhr1-1.xx.fbcdn.net external-lhr10-1.xx.fbcdn.net external-lhr2-1.xx.fbcdn.net external-lhr3-1.xx.fbcdn.net external-lhr4-1.xx.fbcdn.net external-lhr5-1.xx.fbcdn.net external-lhr6-1.xx.fbcdn.net external-lhr7-1.xx.fbcdn.net external-lhr8-1.xx.fbcdn.net external-lhr9-1.xx.fbcdn.net fbcdn-creative-a.akamaihd.net scontent-lhr3-1.xx.fbcdn.net scontent.xx.fbcdn.net scontent.fgdl5-1.fna.fbcdn.net graph.facebook.com b-graph.facebook.com connect.facebook.com cdn.fbsbx.com api.facebook.com edge-mqtt.facebook.com mqtt.c10r.facebook.com portal.fb.com star.c10r.facebook.com star-mini.c10r.facebook.com b-api.facebook.com fb.me bigzipfiles.facebook.com l.facebook.com facebook.com scontent-atl3-1.xx.fbcdn.net static.xx.fbcdn.net edge-chat.messenger.com video.xx.fbcdn.net external-ort2-1.xx.fbcdn.net scontent-ort2-1.xx.fbcdn.net edge-chat.facebook.com scontent-mia3-1.xx.fbcdn.net plex.tv tvdb2.plex.tv pubsub.plex.bz proxy.plex.bz proxy02.pop.ord.plex.bz cpms.spop10.ams.plex.bz meta-db-worker02.pop.ric.plex.bz meta.plex.bz tvthemes.plexapp.com.cdn.cloudflare.net tvthemes.plexapp.com 106c06cd218b007d-b1e8a1331f68446599e96a4b46a050f5.ams.plex.services meta.plex.tv cpms35.spop10.ams.plex.bz proxy.plex.tv metrics.plex.tv pubsub.plex.tv status.plex.tv plex.tv node.plexapp.com nine.plugins.plexapp.com staging.plex.tv app.plex.tv o1.email.plex.tv o2.sg0.plex.tv dashboard.plex.tv gravatar.com thetvdb.com themoviedb.com chtbl.com services.sonarr.tv skyhook.sonarr.tv download.sonarr.tv apt.sonarr.tv forums.sonarr.tv dl.dropboxusercontent.com ns1.dropbox.com ns2.dropbox.com gfwsl.geforce.com 79423.analytics.edgekey.net assets.adobedtm.com nexus.ensighten.com tracking-protection.cdn.mozilla.net telemetry-console.api.playstation.com settings-win.data.microsoft.com v10.vortex-win.data.microsoft.com wdcp.microsoft.com","title":"PiHole Blocklist"},{"location":"Tech/pi-hole-blocklist/#pihole-blocklist","text":"clients4.google.com> clients2.google.com s.youtube.com googleapis.l.google.com www.msftncsi.com outlook.office365.com products.office.com c.s-microsoft.com i.s-microsoft.com login.live.com login.microsoftonline.com dl.delivery.mp.microsoft.com geo-prod.do.dsp.mp.microsoft.com displaycatalog.mp.microsoft.com sls.update.microsoft.com.akadns.net fe3.delivery.dsp.mp.microsoft.com.nsatc.net tlu.dl.delivery.mp.microsoft.com msedge.api.cdp.microsoft.com officeclient.microsoft.com itunes.apple.com s.mzstatic.com appleid.apple.com msftncsi.com ipv6.msftncsi.com captive.apple.com gsp1.apple.com www.apple.com www.appleiphonecell.com spclient.wg.spotify.com apresolve.spotify.com api-tv.spotify.com upload.facebook.com creative.ak.fbcdn.net external-lhr0-1.xx.fbcdn.net external-lhr1-1.xx.fbcdn.net external-lhr10-1.xx.fbcdn.net external-lhr2-1.xx.fbcdn.net external-lhr3-1.xx.fbcdn.net external-lhr4-1.xx.fbcdn.net external-lhr5-1.xx.fbcdn.net external-lhr6-1.xx.fbcdn.net external-lhr7-1.xx.fbcdn.net external-lhr8-1.xx.fbcdn.net external-lhr9-1.xx.fbcdn.net fbcdn-creative-a.akamaihd.net scontent-lhr3-1.xx.fbcdn.net scontent.xx.fbcdn.net scontent.fgdl5-1.fna.fbcdn.net graph.facebook.com b-graph.facebook.com connect.facebook.com cdn.fbsbx.com api.facebook.com edge-mqtt.facebook.com mqtt.c10r.facebook.com portal.fb.com star.c10r.facebook.com star-mini.c10r.facebook.com b-api.facebook.com fb.me bigzipfiles.facebook.com l.facebook.com facebook.com scontent-atl3-1.xx.fbcdn.net static.xx.fbcdn.net edge-chat.messenger.com video.xx.fbcdn.net external-ort2-1.xx.fbcdn.net scontent-ort2-1.xx.fbcdn.net edge-chat.facebook.com scontent-mia3-1.xx.fbcdn.net plex.tv tvdb2.plex.tv pubsub.plex.bz proxy.plex.bz proxy02.pop.ord.plex.bz cpms.spop10.ams.plex.bz meta-db-worker02.pop.ric.plex.bz meta.plex.bz tvthemes.plexapp.com.cdn.cloudflare.net tvthemes.plexapp.com 106c06cd218b007d-b1e8a1331f68446599e96a4b46a050f5.ams.plex.services meta.plex.tv cpms35.spop10.ams.plex.bz proxy.plex.tv metrics.plex.tv pubsub.plex.tv status.plex.tv plex.tv node.plexapp.com nine.plugins.plexapp.com staging.plex.tv app.plex.tv o1.email.plex.tv o2.sg0.plex.tv dashboard.plex.tv gravatar.com thetvdb.com themoviedb.com chtbl.com services.sonarr.tv skyhook.sonarr.tv download.sonarr.tv apt.sonarr.tv forums.sonarr.tv dl.dropboxusercontent.com ns1.dropbox.com ns2.dropbox.com gfwsl.geforce.com 79423.analytics.edgekey.net assets.adobedtm.com nexus.ensighten.com tracking-protection.cdn.mozilla.net telemetry-console.api.playstation.com settings-win.data.microsoft.com v10.vortex-win.data.microsoft.com wdcp.microsoft.com","title":"PiHole Blocklist"},{"location":"Tech/powershell-commands/","text":"Commands/Scripts list all computers in an OU Get-ADComputer -Filter * -SearchBase \"OU=, DC=domain, DC=com\" | Format-Table Name list OUs by distinguished name powershell Get-ADOrganizationalUnit -Filter 'Name -like \"*\"' | Format-Table Name, DistinguishedName -A set unrestricted restriction policy for the current user powershell Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Scope CurrentUser get domain info Get-ADDomain test . com stop and disable a service from text file Get-Service -Name Spooler -ComputerName ( Get-Content C :\\ Users \\ rt \\ notes \\ powershell \\ cylance_disable \\ servers . txt ) | Stop-Service -PassThru | Set-Service -StartupType Disabled launch powershell with different credentials Start Powershell -Credential \"\" get disabled users by account name Get-ADUser -Filter { Enabled -eq $false } | FT samAccountName get domain admins Get-ADGroupmember -Identity \"Domain Admins\" | FT name -A get passwords set to never expire get-aduser -filter * -properties Name , PasswordNeverExpires | where { $_ . passwordNeverExpires -eq \"true\" } | Select-Object Name , Enabled | Export-csv c :\\ working \\ pw_never_expires . csv -NoTypeInformation get user account information get-aduser -filter * -Properties Enabled , samAccountName , LastLogonDate , PasswordLastSet | Export-csv c :\\ powershell \\ password-set . csv -NoTypeInformation get stale users >90d $Days = 90 $Time = ( Get-Date ). Adddays (-( $Days )) Get-ADUser -Filter { LastLogonTimeStamp -lt $Time } -Properties * | Select-Object samAccountName , Enabled , LastLogonDate | Export-csv c :\\ working \\ powershell \\ ad-testing \\ stale-users . csv -NoTypeInformation get stale computers >90d $Days = 90 $Time = ( Get-Date ). Adddays (-( $Days )) Get-ADComputer -server dc_hostname -Filter { LastLogonTimeStamp -lt $Time } -Properties * | Select-Object samAccountName , Enabled , LastLogonDate , DistinguishedName get last logon date of a computer Get-ADComputer -Filter * -Properties * | Sort LastLogonDate | FT Name , LastLogonDate -Autosize get locked account info Get-WinEvent -ComputerName dc_hostname -FilterHashtable @{ logname = 'security' ; id = 4740 } get enabled user count ( Get-ADUser -server dc_hostname -Filter { Enabled -eq $true }). Count test connection to service Test-Connection google . com Test Connection to Server test-netconnection server . domain . com -port 14501 Get AD Users enabled status, company, and division get-aduser -properties * -filter * | Select samaccountname , name , enabled , company , division | Export-Csv -path C :\\ working \\ users . csv","title":"Powershell commands"},{"location":"Tech/powershell-commands/#commandsscripts","text":"","title":"Commands/Scripts"},{"location":"Tech/powershell-commands/#list-all-computers-in-an-ou","text":"Get-ADComputer -Filter * -SearchBase \"OU=, DC=domain, DC=com\" | Format-Table Name","title":"list all computers in an OU"},{"location":"Tech/powershell-commands/#list-ous-by-distinguished-name","text":"powershell Get-ADOrganizationalUnit -Filter 'Name -like \"*\"' | Format-Table Name, DistinguishedName -A","title":"list OUs by distinguished name"},{"location":"Tech/powershell-commands/#set-unrestricted-restriction-policy-for-the-current-user","text":"powershell Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Scope CurrentUser","title":"set unrestricted restriction policy for the current user"},{"location":"Tech/powershell-commands/#get-domain-info","text":"Get-ADDomain test . com","title":"get domain info"},{"location":"Tech/powershell-commands/#stop-and-disable-a-service-from-text-file","text":"Get-Service -Name Spooler -ComputerName ( Get-Content C :\\ Users \\ rt \\ notes \\ powershell \\ cylance_disable \\ servers . txt ) | Stop-Service -PassThru | Set-Service -StartupType Disabled","title":"stop and disable a service from text file"},{"location":"Tech/powershell-commands/#launch-powershell-with-different-credentials","text":"Start Powershell -Credential \"\"","title":"launch powershell with different credentials"},{"location":"Tech/powershell-commands/#get-disabled-users-by-account-name","text":"Get-ADUser -Filter { Enabled -eq $false } | FT samAccountName","title":"get disabled users by account name"},{"location":"Tech/powershell-commands/#get-domain-admins","text":"Get-ADGroupmember -Identity \"Domain Admins\" | FT name -A","title":"get domain admins"},{"location":"Tech/powershell-commands/#get-passwords-set-to-never-expire","text":"get-aduser -filter * -properties Name , PasswordNeverExpires | where { $_ . passwordNeverExpires -eq \"true\" } | Select-Object Name , Enabled | Export-csv c :\\ working \\ pw_never_expires . csv -NoTypeInformation","title":"get passwords set to never expire"},{"location":"Tech/powershell-commands/#get-user-account-information","text":"get-aduser -filter * -Properties Enabled , samAccountName , LastLogonDate , PasswordLastSet | Export-csv c :\\ powershell \\ password-set . csv -NoTypeInformation","title":"get user account information"},{"location":"Tech/powershell-commands/#get-stale-users-90d","text":"$Days = 90 $Time = ( Get-Date ). Adddays (-( $Days )) Get-ADUser -Filter { LastLogonTimeStamp -lt $Time } -Properties * | Select-Object samAccountName , Enabled , LastLogonDate | Export-csv c :\\ working \\ powershell \\ ad-testing \\ stale-users . csv -NoTypeInformation","title":"get stale users &gt;90d"},{"location":"Tech/powershell-commands/#get-stale-computers-90d","text":"$Days = 90 $Time = ( Get-Date ). Adddays (-( $Days )) Get-ADComputer -server dc_hostname -Filter { LastLogonTimeStamp -lt $Time } -Properties * | Select-Object samAccountName , Enabled , LastLogonDate , DistinguishedName","title":"get stale computers &gt;90d"},{"location":"Tech/powershell-commands/#get-last-logon-date-of-a-computer","text":"Get-ADComputer -Filter * -Properties * | Sort LastLogonDate | FT Name , LastLogonDate -Autosize","title":"get last logon date of a computer"},{"location":"Tech/powershell-commands/#get-locked-account-info","text":"Get-WinEvent -ComputerName dc_hostname -FilterHashtable @{ logname = 'security' ; id = 4740 }","title":"get locked account info"},{"location":"Tech/powershell-commands/#get-enabled-user-count","text":"( Get-ADUser -server dc_hostname -Filter { Enabled -eq $true }). Count","title":"get enabled user count"},{"location":"Tech/powershell-commands/#test-connection-to-service","text":"Test-Connection google . com","title":"test connection to service"},{"location":"Tech/powershell-commands/#test-connection-to-server","text":"test-netconnection server . domain . com -port 14501","title":"Test Connection to Server"},{"location":"Tech/powershell-commands/#get-ad-users-enabled-status-company-and-division","text":"get-aduser -properties * -filter * | Select samaccountname , name , enabled , company , division | Export-Csv -path C :\\ working \\ users . csv","title":"Get AD Users enabled status, company, and division"},{"location":"Tech/python-notes/","text":"Python Notes Variables and Simple Data Types string - series of characters, anything inside of quotes is considered a string method - an action that Python can perform on a piece of data every method is followed by a set of (), methods often need more info in those () title() print(name.title()) upper() print(name.upper()) lower() print(name.lower()) useful for string data, often you will want all lower case Combining or Concatenating Strings often useful to combine strings, ex. combining first and last names first_name = \"duke\" last_name = \"nukem\" full_name = first_name + \" \" + last_name print(full_name) Adding Whitespace to Strings with Tabs or Newlines \\n - newline >>> print(\"python\") >>> python \\t - tab >>> print(\"\\tpython\" >>> python Stripping Whitespace rstrip() - strips whitespace to the right lstrip() - strips whitespace to the left strip() - strips whitespace from both sides Avoiding Type Errors with the str() Function Often you will want to use a variables value within a message. eg. age = 23 message = \"Happy \" + age + \"rd Birthday!\" print(message) this will return the following error becuase Python doesn't know what to do with that data Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: can only concatenate str (not \"int\") to str to solve this you have to convert the int to a str age = 23 message = \"Happy \" + str(age) + \"rd Birthday!\" print(message) Lists methods for working with lists .insert() .append() .pop() del .remove() list - collection of items in a particular order [] indicate a list lists are ordered collections, you can access any item in a list by telling python the location, or index print(bicycles[0].title()) to access the last element in a list, you would use [-1] print(bicycles[-1]) add elements to a list with .append() and .insert() append adds to the end, insert asks for a position motorcycles.insert(0, 'ducati') delete items from a list with del del motorcycles[-1] Looping range() - used to generate a series of numbers for value in range(1,5): print(value) find minimum, maximum, and sum of a list of numbers min() max() sum() list comprehension allows you to generate a list in one line of code, combines for loop and creation squares = [value*2 for value in range(1,11)] Dictionaires a dictionary is a collection of key-value pairs each key is connected to a value and you can use a key to access the value associated with that key a keys value can be number, string, list, or another dictionary dictionary is wrapped in braces with a series of key-value pairs inside the braces alien_0 = {'color': 'green', 'points': 5} to access values in a dictionary, give the name of the dictionary and place the key inside [] print(alien_0['color']) you can add values to dictionaries at any time removing key-value pairs del alien_0['points'] for loop with dictionaries for key, value in user_0.items(): print(\"\\nKey: \" + key) print(\"Value: \" + value) for k, v in user_0.items() - create names for the two variables that will hold the key and value in each key-value pair","title":"Python Notes"},{"location":"Tech/python-notes/#python-notes","text":"","title":"Python Notes"},{"location":"Tech/python-notes/#variables-and-simple-data-types","text":"string - series of characters, anything inside of quotes is considered a string method - an action that Python can perform on a piece of data every method is followed by a set of (), methods often need more info in those () title() print(name.title()) upper() print(name.upper()) lower() print(name.lower()) useful for string data, often you will want all lower case","title":"Variables and Simple Data Types"},{"location":"Tech/python-notes/#combining-or-concatenating-strings","text":"often useful to combine strings, ex. combining first and last names first_name = \"duke\" last_name = \"nukem\" full_name = first_name + \" \" + last_name print(full_name)","title":"Combining or Concatenating Strings"},{"location":"Tech/python-notes/#adding-whitespace-to-strings-with-tabs-or-newlines","text":"\\n - newline >>> print(\"python\") >>> python \\t - tab >>> print(\"\\tpython\" >>> python","title":"Adding Whitespace to Strings with Tabs or Newlines"},{"location":"Tech/python-notes/#stripping-whitespace","text":"rstrip() - strips whitespace to the right lstrip() - strips whitespace to the left strip() - strips whitespace from both sides","title":"Stripping Whitespace"},{"location":"Tech/python-notes/#avoiding-type-errors-with-the-str-function","text":"Often you will want to use a variables value within a message. eg. age = 23 message = \"Happy \" + age + \"rd Birthday!\" print(message) this will return the following error becuase Python doesn't know what to do with that data Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: can only concatenate str (not \"int\") to str to solve this you have to convert the int to a str age = 23 message = \"Happy \" + str(age) + \"rd Birthday!\" print(message)","title":"Avoiding Type Errors with the str() Function"},{"location":"Tech/python-notes/#lists","text":"methods for working with lists .insert() .append() .pop() del .remove() list - collection of items in a particular order [] indicate a list lists are ordered collections, you can access any item in a list by telling python the location, or index print(bicycles[0].title()) to access the last element in a list, you would use [-1] print(bicycles[-1]) add elements to a list with .append() and .insert() append adds to the end, insert asks for a position motorcycles.insert(0, 'ducati') delete items from a list with del del motorcycles[-1]","title":"Lists"},{"location":"Tech/python-notes/#looping","text":"range() - used to generate a series of numbers for value in range(1,5): print(value) find minimum, maximum, and sum of a list of numbers min() max() sum() list comprehension allows you to generate a list in one line of code, combines for loop and creation squares = [value*2 for value in range(1,11)]","title":"Looping"},{"location":"Tech/python-notes/#dictionaires","text":"a dictionary is a collection of key-value pairs each key is connected to a value and you can use a key to access the value associated with that key a keys value can be number, string, list, or another dictionary dictionary is wrapped in braces with a series of key-value pairs inside the braces alien_0 = {'color': 'green', 'points': 5} to access values in a dictionary, give the name of the dictionary and place the key inside [] print(alien_0['color']) you can add values to dictionaries at any time removing key-value pairs del alien_0['points'] for loop with dictionaries for key, value in user_0.items(): print(\"\\nKey: \" + key) print(\"Value: \" + value) for k, v in user_0.items() - create names for the two variables that will hold the key and value in each key-value pair","title":"Dictionaires"},{"location":"Tech/useful-commands/","text":"Useful Linux Commands Shell delete text in a file sed \"/TEXT/d\" < inputfile append date to file touch \"foo.backup.$(date +%F_%R)\" foo.backup.2013-10-16_19:25 scp most recent file $ RECENT=$(ssh someone@example.com ls -lrt /remote/path/ | awk '/.ubx/ { f=$NF }; END { print f }');` $ scp someone@example.com:/remote/path/${RECENT} /local/path/${RECENT}; burn iso to usb drive dd bs=4M if=/path/to/archlinux.iso of=/dev/sdx status=progress oflag=sync Misc check status of mdadm RAID cat /proc/mdstat mount smb share on Linux mount -t cifs -o username=USERNAME,password=PASSWORD,uid=UID,gid=GID //HOST/SHARE /local/mount/point add smb share to fstab create a file in /home/user named .smbcredentials inside that file create twi lines - username=USERNAME password=PASSWORD //192.168.88.147/red/media /mnt/media cifs credentials=/home/rt/.smbcredentials,iocharset=utf8,gid=1000,uid=1000,file_mode=0777,dir_mode=0777,sec=ntlm 0 0 backup mysql db mysqldump -h localhost -u rt -p --default-character-set=binary wiki > backup.sql restore mysql db mysql -u root -p my_wiki < backup.sql Docker start container on a port and link with another docker run --name mediawiki -p 8080:80 --link mediawiki-mysql:mysql -d mediawiki list running containers docker ps start a conainter on a port docker run --name mediawiki -p 8080:80 -d mediawiki kill a container docker kill 233fce5bcd21 copy files to a container docker cp LocalSettings.php mediawiki:/var/www/html list resource usage of running containers docker cp LocalSettings.php mediawiki:/var/www/html launch a bash shell in a conatiner docker exec -it mediawiki-mysql bash show stopped docker containers docker ps -a | grep Exit UniFi show arp table cat /proc/net/arp Proxmox Create volume pvcreate /dev/sd** Create volume group vgcreate NAME /dev/sd**","title":"Useful Linux Commands"},{"location":"Tech/useful-commands/#useful-linux-commands","text":"","title":"Useful Linux Commands"},{"location":"Tech/useful-commands/#shell","text":"delete text in a file sed \"/TEXT/d\" < inputfile append date to file touch \"foo.backup.$(date +%F_%R)\" foo.backup.2013-10-16_19:25 scp most recent file $ RECENT=$(ssh someone@example.com ls -lrt /remote/path/ | awk '/.ubx/ { f=$NF }; END { print f }');` $ scp someone@example.com:/remote/path/${RECENT} /local/path/${RECENT}; burn iso to usb drive dd bs=4M if=/path/to/archlinux.iso of=/dev/sdx status=progress oflag=sync","title":"Shell"},{"location":"Tech/useful-commands/#misc","text":"check status of mdadm RAID cat /proc/mdstat mount smb share on Linux mount -t cifs -o username=USERNAME,password=PASSWORD,uid=UID,gid=GID //HOST/SHARE /local/mount/point add smb share to fstab create a file in /home/user named .smbcredentials inside that file create twi lines - username=USERNAME password=PASSWORD //192.168.88.147/red/media /mnt/media cifs credentials=/home/rt/.smbcredentials,iocharset=utf8,gid=1000,uid=1000,file_mode=0777,dir_mode=0777,sec=ntlm 0 0 backup mysql db mysqldump -h localhost -u rt -p --default-character-set=binary wiki > backup.sql restore mysql db mysql -u root -p my_wiki < backup.sql","title":"Misc"},{"location":"Tech/useful-commands/#docker","text":"start container on a port and link with another docker run --name mediawiki -p 8080:80 --link mediawiki-mysql:mysql -d mediawiki list running containers docker ps start a conainter on a port docker run --name mediawiki -p 8080:80 -d mediawiki kill a container docker kill 233fce5bcd21 copy files to a container docker cp LocalSettings.php mediawiki:/var/www/html list resource usage of running containers docker cp LocalSettings.php mediawiki:/var/www/html launch a bash shell in a conatiner docker exec -it mediawiki-mysql bash show stopped docker containers docker ps -a | grep Exit","title":"Docker"},{"location":"Tech/useful-commands/#unifi","text":"show arp table cat /proc/net/arp","title":"UniFi"},{"location":"Tech/useful-commands/#proxmox","text":"Create volume pvcreate /dev/sd** Create volume group vgcreate NAME /dev/sd**","title":"Proxmox"}]}